{"cells":[{"cell_type":"markdown","metadata":{"_uuid":"592be02f821630fd987b3304f1c619c0c4e2a94d"},"source":["# Tae-Seung Kim Module 5\n"]},{"cell_type":"markdown","metadata":{},"source":["## Initial Section loaded from the linked kaggle notebook\n","\n","In the kernel \"The fallacy of encoding assetCode\", @marketneutral makes the point that encoding assetCode and using either of the lightGBM built in feature importances (split and gain) results in assetCode being a significant feature. The advice was \"Don't encode assetCode\".\n","\n","In this kernel, we experiment with using MDA feature importances as described in \"Advances in Financial Machine Learning\" by Marcos Lopez de Prado.\n","\n","We use the code from @marketneutral's kernel to generate random data for the test.\n","\n","Using this process, assetCode has no importance."]},{"cell_type":"code","execution_count":158,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"68ae9626dee508fbfc4670beb9bbbf4ddec75669","trusted":true},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import shap\n","from sklearn.model_selection import train_test_split\n","import seaborn as sns\n","from sklearn import preprocessing\n","from sklearn.ensemble import RandomForestClassifier\n","import sklearn.metrics as metrics\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import PrecisionRecallDisplay, f1_score, average_precision_score, roc_curve, precision_recall_fscore_support, precision_recall_curve, confusion_matrix, classification_report"]},{"cell_type":"code","execution_count":159,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"a0de91cc0f7d7447a9e4eccfa5dacda21d94e728","trusted":true},"outputs":[],"source":["plt.style.use('seaborn-v0_8')\n","plt.rcParams['figure.figsize'] = 12, 7"]},{"cell_type":"code","execution_count":160,"metadata":{},"outputs":[],"source":["class rfmodel:\n","    # on creation\n","    def __init__(self, name, data, seed=1):\n","        self.name = name\n","        self.xdata = data.copy().drop(['date','target'], axis=1)\n","        #dividends included is the target\n","        self.ydata = data['target'].copy()\n","        #any target giving > 0 returns is a good enough trade\n","        self.X_Train, self.X_Test, self.Y_Train, self.Y_Test = train_test_split(self.xdata, self.ydata, test_size=(1/3), random_state=1)\n","        self.seed = seed\n","        self.model = RandomForestClassifier(n_estimators=100,random_state=seed)\n","        \n","\n","    def featImpMDA_classify(self,cv=10):\n","        X = self.xdata\n","        y = self.ydata\n","        np.random.seed(self.seed)\n","        # feat importance based on OOS score reduction\n","        print('start MDA',dt.datetime.now())\n","        from sklearn.metrics import log_loss\n","        cvGen=KFold(n_splits=cv)\n","        scr0,scr1=pd.Series(dtype='float64'),pd.DataFrame(columns=X.columns)\n","        for i,(train,test) in enumerate(cvGen.split(X=X)):\n","            print('   Split',i+1)\n","            X0, y0=X.iloc[train,:],y.iloc[train]\n","            X1, y1=X.iloc[test,:],y.iloc[test]  \n","            fit=self.model.fit(X=X0,y=y0.values.ravel())\n","            pred=fit.predict_proba(X1)\n","            #neg log loss from snippet 8.3\n","            scr0.loc[i]=-log_loss(y1,pred[:,1], sample_weight=None, labels=self.model.classes_)\n","            for j in X.columns:\n","                X1_=X1.copy(deep=True)\n","                np.random.shuffle(X1_[j].values) # permutation of a single column\n","                pred=fit.predict_proba(X1_)\n","            \n","                scr1.loc[i,j]=-log_loss(y1,pred[:,1], sample_weight=None, labels=self.model.classes_)\n","        #neg log loss from snippet 8.3\n","        imp=(-scr1).add(scr0,axis=0)\n","        imp=imp/-scr1\n","        imp=pd.concat({'mean':imp.mean(),'std':imp.std()*imp.shape[0]**-.5},axis=1)\n","        print('end MDA',dt.datetime.now())\n","        self.imp_raw = imp\n","        self.imp = self.imp_raw.reset_index().rename(index=int,\n","                                                columns={\"index\":\"Feature\",'mean':'Importance'}, \n","                                                inplace=False).set_index('Feature')\n","        self.imp = self.imp.sort_values(by='Importance')\n","        self.scr0 = scr0\n","        self.scr1 = scr1\n","\n","    def fit(self):\n","        self.model.fit(self.X_Train, self.Y_Train)\n","\n","    def pred(self):\n","        self.Y_Pred_Train = self.model.predict(self.X_Train)\n","        self.Y_Pred_Test = self.model.predict(self.X_Test)\n","        self.train_probs = self.model.predict_proba(self.X_Train)\n","        self.test_probs = self.model.predict_proba(self.X_Test)\n","        self.train_probs = self.train_probs[:,1]\n","        self.test_probs = self.test_probs[:,1]\n","        \n","\n","    def getAccuracy(self):\n","        self.precision_train, self.precision_train, self.train_threshold = metrics.precision_recall_curve(self.Y_Train, self.train_probs)\n","        self.precision_test, self.precision_test, self.test_threshold = metrics.precision_recall_curve(self.Y_Test, self.test_probs)\n","        self.auc_train = average_precision_score(self.Y_Train, self.Y_Pred_Train)\n","        self.auc_test = average_precision_score(self.Y_Test, self.Y_Pred_Test)\n","        self.train_acc = metrics.accuracy_score(self.Y_Train, self.Y_Pred_Train)\n","        self.test_acc = metrics.accuracy_score(self.Y_Test, self.Y_Pred_Test)\n","        self.f1_train = f1_score(self.Y_Train, self.Y_Pred_Train)\n","        self.f1_test = f1_score(self.Y_Test, self.Y_Pred_Test)\n","        self.bigscoretest = precision_recall_fscore_support(self.Y_Test, self.Y_Pred_Test, average='binary')\n","        self.bigscoretrain = precision_recall_fscore_support(self.Y_Train, self.Y_Pred_Train, average='binary')\n","\n","    def makePRplot(self):\n","        \n","        self.plot1 = PrecisionRecallDisplay.from_predictions(self.Y_Test, self.Y_Pred_Test, drawstyle=\"default\")\n","        self.plot1.ax_.set_title(self.name + \" Test Precision Recall Curve\")\n","        self.plot2 = PrecisionRecallDisplay.from_predictions(self.Y_Train, self.Y_Pred_Train, drawstyle=\"default\")\n","        self.plot2.ax_.set_title(self.name + \" Train Precision Recall Curve\")\n","        #plt.show()\n","    \n","    def plot_importances(self, save=None, xrot=0, tickstep=3,\n","                     label_fontsize=12,\n","                     figsize=None, scalefig=(1.0, 1.0), show=True):\n","        \"\"\"\n","        Given an array or data frame of importances, plot a horizontal bar chart\n","        showing the importance values.\n","\n","        :param df_importances: A data frame with Feature, Importance columns\n","        :type df_importances: pd.DataFrame\n","        :param save: A filename identifying where to save the image.\n","        :param xrot: Degrees to rotate importance (X axis) labels\n","        :type xrot: int\n","        :param tickstep: How many ticks to skip in X axis\n","        :type tickstep: int\n","        :param label_fontsize:  The font size for the column names and x ticks\n","        :type label_fontsize:  int\n","        :param figsize: Specify width and height of image (width,height)\n","        :type figsize: 2-tuple of floats\n","        :param scalefig: Scale width and height of image (widthscale,heightscale)\n","        :type scalefig: 2-tuple of floats\n","        :param show: Execute plt.show() if true (default is True). Sometimes\n","                    we want to draw multiple things before calling plt.show()\n","        :type show: bool\n","        :return: None\n","\n","        SAMPLE CODE\n","\n","        rf = RandomForestRegressor(n_estimators=100, n_jobs=-1, oob_score=True)\n","        X_train, y_train = ..., ...\n","        rf.fit(X_train, y_train)\n","        imp = importances(rf, X_test, y_test)\n","        plot_importances(imp)\n","        \"\"\"\n","        df_importances = self.imp\n","\n","        I = df_importances\n","\n","        if figsize:\n","            fig = plt.figure(figsize=figsize)\n","        elif scalefig:\n","            fig = plt.figure()\n","            w, h = fig.get_size_inches()\n","            fig.set_size_inches(w * scalefig[0], h * scalefig[1], forward=True)\n","        else:\n","            fig = plt.figure()\n","        ax = plt.gca()\n","        labels = []\n","        for col in I.index:\n","            if isinstance(col, list):\n","                labels.append('\\n'.join(col))\n","            else:\n","                labels.append(col)\n","\n","        for tick in ax.get_xticklabels():\n","            tick.set_size(label_fontsize)\n","        for tick in ax.get_yticklabels():\n","            tick.set_size(label_fontsize)\n","        ax.barh(np.arange(len(I.index)), I.Importance, height=0.6, tick_label=labels)\n","\n","        # rotate x-ticks\n","        if xrot is not None:\n","            plt.xticks(rotation=xrot)\n","\n","        # xticks freq\n","        xticks = ax.get_xticks()\n","        nticks = len(xticks)\n","        new_ticks = xticks[np.arange(0, nticks, step=tickstep)]\n","        ax.set_xticks(new_ticks)\n","\n","        if save:\n","            plt.savefig(save, bbox_inches=\"tight\", pad_inches=0.03)\n","        if show:\n","            plt.show()\n","\n"]},{"cell_type":"code","execution_count":161,"metadata":{},"outputs":[],"source":["#load data\n","xdat = pd.read_csv('X_processed_final.csv')\n","ydat = pd.read_csv('y_final.csv')\n","combined = pd.concat([xdat, ydat], axis=1)\n","combined.rename(columns={'ret':'target', 'yyyymm':'date'}, inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Question1\n","\n","Setting the random seed to 1, and using the same dataset as in the Module 4 assignment Download the same dataset as in the Module 4 assignment, compute the feature importance scores of each feature by applying the featImportance function (Snippet 8.8 in AFML) on the 10 cross validation sets within the train set defined there.\n","\n"," Why can’t FS be applied to the train set as a whole? (For a hint, please read assetCode with MDA using random dataLinks to an external site..) (16 points)\n","\n","Applying it to the entire train test could be a mostly mistake due to overfitting and train/test leaks. Our code is mostly focused on reducing overfitting while in Marcos Lopez de Prado's code, he accounts for removing the possibility of train test leakage by pruging & embargoing. \n","\n","Overfitting is bad because it boosts training scores while underperforming against new data. \n"]},{"cell_type":"code","execution_count":162,"metadata":{},"outputs":[],"source":["basemodel = rfmodel('basemodel', combined)"]},{"cell_type":"code","execution_count":163,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["start MDA 2024-02-03 17:10:57.739500\n","   Split 1\n"]},{"name":"stdout","output_type":"stream","text":["   Split 2\n","   Split 3\n","   Split 4\n","   Split 5\n","   Split 6\n","   Split 7\n","   Split 8\n","   Split 9\n","   Split 10\n","end MDA 2024-02-03 17:11:04.536501\n"]}],"source":["basemodel.featImpMDA_classify()"]},{"cell_type":"code","execution_count":164,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Importance</th>\n","      <th>std</th>\n","    </tr>\n","    <tr>\n","      <th>Feature</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>ntis</th>\n","      <td>-0.008591</td>\n","      <td>0.004666</td>\n","    </tr>\n","    <tr>\n","      <th>svar</th>\n","      <td>-0.005997</td>\n","      <td>0.003306</td>\n","    </tr>\n","    <tr>\n","      <th>b/m_FD</th>\n","      <td>-0.001717</td>\n","      <td>0.003911</td>\n","    </tr>\n","    <tr>\n","      <th>corpr</th>\n","      <td>-0.001279</td>\n","      <td>0.003166</td>\n","    </tr>\n","    <tr>\n","      <th>d/e</th>\n","      <td>-0.000849</td>\n","      <td>0.003109</td>\n","    </tr>\n","    <tr>\n","      <th>dfr</th>\n","      <td>0.000552</td>\n","      <td>0.002402</td>\n","    </tr>\n","    <tr>\n","      <th>lty_FD</th>\n","      <td>0.000590</td>\n","      <td>0.001541</td>\n","    </tr>\n","    <tr>\n","      <th>tms</th>\n","      <td>0.001301</td>\n","      <td>0.003955</td>\n","    </tr>\n","    <tr>\n","      <th>ltr</th>\n","      <td>0.003176</td>\n","      <td>0.004195</td>\n","    </tr>\n","    <tr>\n","      <th>dfy</th>\n","      <td>0.005023</td>\n","      <td>0.005022</td>\n","    </tr>\n","    <tr>\n","      <th>infl</th>\n","      <td>0.007154</td>\n","      <td>0.006951</td>\n","    </tr>\n","    <tr>\n","      <th>e/p</th>\n","      <td>0.007938</td>\n","      <td>0.005308</td>\n","    </tr>\n","    <tr>\n","      <th>tbl_FD</th>\n","      <td>0.009122</td>\n","      <td>0.002730</td>\n","    </tr>\n","    <tr>\n","      <th>d/p</th>\n","      <td>0.033830</td>\n","      <td>0.009905</td>\n","    </tr>\n","    <tr>\n","      <th>d/y</th>\n","      <td>0.045858</td>\n","      <td>0.013417</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         Importance       std\n","Feature                      \n","ntis      -0.008591  0.004666\n","svar      -0.005997  0.003306\n","b/m_FD    -0.001717  0.003911\n","corpr     -0.001279  0.003166\n","d/e       -0.000849  0.003109\n","dfr        0.000552  0.002402\n","lty_FD     0.000590  0.001541\n","tms        0.001301  0.003955\n","ltr        0.003176  0.004195\n","dfy        0.005023  0.005022\n","infl       0.007154  0.006951\n","e/p        0.007938  0.005308\n","tbl_FD     0.009122  0.002730\n","d/p        0.033830  0.009905\n","d/y        0.045858  0.013417"]},"execution_count":164,"metadata":{},"output_type":"execute_result"}],"source":["basemodel.imp"]},{"cell_type":"code","execution_count":165,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 864x504 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["basemodel.plot_importances()"]},{"cell_type":"markdown","metadata":{},"source":["## Question 2\n","\n","If you obtain a different FI score for a feature in each cross validation subset, how is the overall FI score computed? (8 points)\n","\n","For each fold, every feature gets a log loss score. Then once all the folds are done the average is computed to give the score across all the folds.\n","\n","In our example adapted from snippet 8.3 we focus on measuring the improvement of log loss via shuffling. \n","\n","scr0.loc[i]=-log_loss(y1,pred[:,1], sample_weight=None, labels=clf.classes_)\n","\n","The above snippet establishes the baseline scr0. \n","\n","The following for loop in our code then calculates scr1. \n","\n","We the take the new score (-scr1).add(scr0, axis=0) and add it to the base score. \n","\n","so scr1 + scr0 / scr1 is the final measurement that tells us how important the feature is. "]},{"cell_type":"code","execution_count":166,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Importance</th>\n","      <th>std</th>\n","    </tr>\n","    <tr>\n","      <th>Feature</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>ntis</th>\n","      <td>-0.008591</td>\n","      <td>0.004666</td>\n","    </tr>\n","    <tr>\n","      <th>svar</th>\n","      <td>-0.005997</td>\n","      <td>0.003306</td>\n","    </tr>\n","    <tr>\n","      <th>b/m_FD</th>\n","      <td>-0.001717</td>\n","      <td>0.003911</td>\n","    </tr>\n","    <tr>\n","      <th>corpr</th>\n","      <td>-0.001279</td>\n","      <td>0.003166</td>\n","    </tr>\n","    <tr>\n","      <th>d/e</th>\n","      <td>-0.000849</td>\n","      <td>0.003109</td>\n","    </tr>\n","    <tr>\n","      <th>dfr</th>\n","      <td>0.000552</td>\n","      <td>0.002402</td>\n","    </tr>\n","    <tr>\n","      <th>lty_FD</th>\n","      <td>0.000590</td>\n","      <td>0.001541</td>\n","    </tr>\n","    <tr>\n","      <th>tms</th>\n","      <td>0.001301</td>\n","      <td>0.003955</td>\n","    </tr>\n","    <tr>\n","      <th>ltr</th>\n","      <td>0.003176</td>\n","      <td>0.004195</td>\n","    </tr>\n","    <tr>\n","      <th>dfy</th>\n","      <td>0.005023</td>\n","      <td>0.005022</td>\n","    </tr>\n","    <tr>\n","      <th>infl</th>\n","      <td>0.007154</td>\n","      <td>0.006951</td>\n","    </tr>\n","    <tr>\n","      <th>e/p</th>\n","      <td>0.007938</td>\n","      <td>0.005308</td>\n","    </tr>\n","    <tr>\n","      <th>tbl_FD</th>\n","      <td>0.009122</td>\n","      <td>0.002730</td>\n","    </tr>\n","    <tr>\n","      <th>d/p</th>\n","      <td>0.033830</td>\n","      <td>0.009905</td>\n","    </tr>\n","    <tr>\n","      <th>d/y</th>\n","      <td>0.045858</td>\n","      <td>0.013417</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         Importance       std\n","Feature                      \n","ntis      -0.008591  0.004666\n","svar      -0.005997  0.003306\n","b/m_FD    -0.001717  0.003911\n","corpr     -0.001279  0.003166\n","d/e       -0.000849  0.003109\n","dfr        0.000552  0.002402\n","lty_FD     0.000590  0.001541\n","tms        0.001301  0.003955\n","ltr        0.003176  0.004195\n","dfy        0.005023  0.005022\n","infl       0.007154  0.006951\n","e/p        0.007938  0.005308\n","tbl_FD     0.009122  0.002730\n","d/p        0.033830  0.009905\n","d/y        0.045858  0.013417"]},"execution_count":166,"metadata":{},"output_type":"execute_result"}],"source":["basemodel.imp"]},{"cell_type":"markdown","metadata":{},"source":["## Question 3\n","\n","What are the 5 most important features? What are the features with above-average FI scores?\n","\n","d/y, d/p, tbl_FD, e/p, infl are the top 5 and the ones with above-average FI scores"]},{"cell_type":"code","execution_count":167,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Importance</th>\n","      <th>std</th>\n","    </tr>\n","    <tr>\n","      <th>Feature</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>d/y</th>\n","      <td>0.045858</td>\n","      <td>0.013417</td>\n","    </tr>\n","    <tr>\n","      <th>d/p</th>\n","      <td>0.033830</td>\n","      <td>0.009905</td>\n","    </tr>\n","    <tr>\n","      <th>tbl_FD</th>\n","      <td>0.009122</td>\n","      <td>0.002730</td>\n","    </tr>\n","    <tr>\n","      <th>e/p</th>\n","      <td>0.007938</td>\n","      <td>0.005308</td>\n","    </tr>\n","    <tr>\n","      <th>infl</th>\n","      <td>0.007154</td>\n","      <td>0.006951</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         Importance       std\n","Feature                      \n","d/y        0.045858  0.013417\n","d/p        0.033830  0.009905\n","tbl_FD     0.009122  0.002730\n","e/p        0.007938  0.005308\n","infl       0.007154  0.006951"]},"execution_count":167,"metadata":{},"output_type":"execute_result"}],"source":["basemodel.imp.sort_values(by='Importance', ascending=False).head(5)"]},{"cell_type":"code","execution_count":168,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["mean of all FI scores: 0.0064\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Importance</th>\n","      <th>std</th>\n","    </tr>\n","    <tr>\n","      <th>Feature</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>d/y</th>\n","      <td>0.045858</td>\n","      <td>0.013417</td>\n","    </tr>\n","    <tr>\n","      <th>d/p</th>\n","      <td>0.033830</td>\n","      <td>0.009905</td>\n","    </tr>\n","    <tr>\n","      <th>tbl_FD</th>\n","      <td>0.009122</td>\n","      <td>0.002730</td>\n","    </tr>\n","    <tr>\n","      <th>e/p</th>\n","      <td>0.007938</td>\n","      <td>0.005308</td>\n","    </tr>\n","    <tr>\n","      <th>infl</th>\n","      <td>0.007154</td>\n","      <td>0.006951</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         Importance       std\n","Feature                      \n","d/y        0.045858  0.013417\n","d/p        0.033830  0.009905\n","tbl_FD     0.009122  0.002730\n","e/p        0.007938  0.005308\n","infl       0.007154  0.006951"]},"execution_count":168,"metadata":{},"output_type":"execute_result"}],"source":["all_avg = basemodel.imp['Importance'].mean()\n","print(f'mean of all FI scores: {all_avg:.4f}')\n","basemodel.imp[basemodel.imp['Importance'] > all_avg].sort_values(by='Importance', ascending=False)"]},{"cell_type":"markdown","metadata":{},"source":["## Question 4\n","\n","If you use only those above-average features as input, and retrain a RF as in the Module 4 assignment to predict the same labels, do any of the performance metrics improve? (16 points)\n","\n","First we fit the feature selected model the exact same way we did the original model. Then we got the scores.\n","\n","\n","\n","| model                  |   precision_train |   recall_train |   f1_train |   auc_train |   precision_test |   recall_test |   f1_test |   auc_test |\n","|:-----------------------|------------------:|---------------:|-----------:|------------:|-----------------:|--------------:|----------:|-----------:|\n","| basemodel               |          0.978593 |       0.963855 |   0.971168 |    0.96377  |         0.96988  |      0.964072 |  0.966967 |   0.955511 |\n","| feature_selected_model |          0.990683 |       0.960843 |   0.975535 |    0.974152 |         0.975309 |      0.946108 |  0.960486 |   0.953464 |\n","\n","We can see that precision increases in both the train and test dataset.\n","\n","However there is a slight decrease in recall, f1, and auc_pr scores.  F1 and auc_pr had a slight increase in train but did worse in the recall. \n"]},{"cell_type":"code","execution_count":169,"metadata":{},"outputs":[],"source":["feature_selected_model = rfmodel('feature_selected_model', \n","                                 combined[['d/y', 'd/p', 'tbl_FD', 'e/p', 'infl','target','date']])"]},{"cell_type":"code","execution_count":170,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["start MDA 2024-02-03 17:11:04.785697\n","   Split 1\n","   Split 2\n","   Split 3\n","   Split 4\n","   Split 5\n","   Split 6\n","   Split 7\n","   Split 8\n","   Split 9\n","   Split 10\n","end MDA 2024-02-03 17:11:09.435828\n"]}],"source":["mod_list = [basemodel, feature_selected_model]\n","\n","feature_selected_model.featImpMDA_classify()\n","feature_selected_model.pred()\n","feature_selected_model.getAccuracy()\n","\n","\n","basemodel.pred()\n","basemodel.getAccuracy()\n","\n","bigholder = []\n","for x in mod_list:\n","    smallholder = {}\n","    smallholder['model'] = x.name\n","    smallholder['precision_train'] = x.bigscoretrain[0]\n","    smallholder['recall_train'] = x.bigscoretrain[1]\n","    smallholder['f1_train'] = x.bigscoretrain[2]\n","    smallholder['auc_train'] = x.auc_train\n","    smallholder['precision_test'] = x.bigscoretest[0]\n","    smallholder['recall_test'] = x.bigscoretest[1]\n","    smallholder['f1_test'] = x.bigscoretest[2]\n","    smallholder['auc_test'] = x.auc_test\n","    bigholder.append(smallholder)\n","    "]},{"cell_type":"code","execution_count":171,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>precision_train</th>\n","      <th>recall_train</th>\n","      <th>f1_train</th>\n","      <th>auc_train</th>\n","      <th>precision_test</th>\n","      <th>recall_test</th>\n","      <th>f1_test</th>\n","      <th>auc_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>basemodel</td>\n","      <td>0.978593</td>\n","      <td>0.963855</td>\n","      <td>0.971168</td>\n","      <td>0.963770</td>\n","      <td>0.969880</td>\n","      <td>0.964072</td>\n","      <td>0.966967</td>\n","      <td>0.955511</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>feature_selected_model</td>\n","      <td>0.990683</td>\n","      <td>0.960843</td>\n","      <td>0.975535</td>\n","      <td>0.974152</td>\n","      <td>0.975309</td>\n","      <td>0.946108</td>\n","      <td>0.960486</td>\n","      <td>0.953464</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    model  precision_train  recall_train  f1_train  auc_train  \\\n","0               basemodel         0.978593      0.963855  0.971168   0.963770   \n","1  feature_selected_model         0.990683      0.960843  0.975535   0.974152   \n","\n","   precision_test  recall_test   f1_test  auc_test  \n","0        0.969880     0.964072  0.966967  0.955511  \n","1        0.975309     0.946108  0.960486  0.953464  "]},"execution_count":171,"metadata":{},"output_type":"execute_result"}],"source":["scores_df = pd.DataFrame(bigholder)\n","scores_df"]},{"cell_type":"code","execution_count":172,"metadata":{},"outputs":[{"data":{"text/plain":["'| model                  |   precision_train |   recall_train |   f1_train |   auc_train |   precision_test |   recall_test |   f1_test |   auc_test |\\n|:-----------------------|------------------:|---------------:|-----------:|------------:|-----------------:|--------------:|----------:|-----------:|\\n| basemodel              |          0.978593 |       0.963855 |   0.971168 |    0.96377  |         0.96988  |      0.964072 |  0.966967 |   0.955511 |\\n| feature_selected_model |          0.990683 |       0.960843 |   0.975535 |    0.974152 |         0.975309 |      0.946108 |  0.960486 |   0.953464 |'"]},"execution_count":172,"metadata":{},"output_type":"execute_result"}],"source":["scores_df.to_markdown(index=False)"]},{"cell_type":"markdown","metadata":{},"source":["## Question 5\n","\n","Now set the random seed to 2, and recompute #3. Are they different? (Hint: see Man, Xin and Chan, Ernest. 2021. “The Best Way to Select Features?\". The Journal of Financial Data Science, Vol 3, Issue 1.) (8 points)\n","\n","In Q3: d/y, d/p, tbl_FD, e/p, infl are the top 5 and the ones with above-average FI scores.\n","\n","Now:\n","\n","d/y, d/p, corpr, e/p/ infl are the top 5.\n","\n","d/y, d/p, corpr, e/p are now the 4 with above average scores.\n","\n","MDA is the least stable when considered with LIME and SHAP. So we could assume that LIME/SHAP should be stable across more random seeds (due to them converging closer to 0) which would mean that across random seeds, we would not see features drop in or out. With MDA, I assume we could monte carlo it and run a bunch of different seeds then see which features pop in or out.\n"]},{"cell_type":"code","execution_count":173,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["start MDA 2024-02-03 17:11:09.591072\n","   Split 1\n"]},{"name":"stdout","output_type":"stream","text":["   Split 2\n","   Split 3\n","   Split 4\n","   Split 5\n","   Split 6\n","   Split 7\n","   Split 8\n","   Split 9\n","   Split 10\n","end MDA 2024-02-03 17:11:16.433666\n"]}],"source":["rs2base = rfmodel('rs2base', combined, seed=2)\n","rs2base.featImpMDA_classify()"]},{"cell_type":"code","execution_count":174,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Importance</th>\n","      <th>std</th>\n","    </tr>\n","    <tr>\n","      <th>Feature</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>d/y</th>\n","      <td>0.025970</td>\n","      <td>0.008850</td>\n","    </tr>\n","    <tr>\n","      <th>d/p</th>\n","      <td>0.023451</td>\n","      <td>0.005185</td>\n","    </tr>\n","    <tr>\n","      <th>corpr</th>\n","      <td>0.011250</td>\n","      <td>0.006746</td>\n","    </tr>\n","    <tr>\n","      <th>e/p</th>\n","      <td>0.006753</td>\n","      <td>0.004698</td>\n","    </tr>\n","    <tr>\n","      <th>infl</th>\n","      <td>0.003653</td>\n","      <td>0.004613</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         Importance       std\n","Feature                      \n","d/y        0.025970  0.008850\n","d/p        0.023451  0.005185\n","corpr      0.011250  0.006746\n","e/p        0.006753  0.004698\n","infl       0.003653  0.004613"]},"execution_count":174,"metadata":{},"output_type":"execute_result"}],"source":["rs2base.imp.sort_values(by='Importance', ascending=False).head(5)"]},{"cell_type":"code","execution_count":175,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["mean of all FI scores: 0.0064\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Importance</th>\n","      <th>std</th>\n","    </tr>\n","    <tr>\n","      <th>Feature</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>d/y</th>\n","      <td>0.025970</td>\n","      <td>0.008850</td>\n","    </tr>\n","    <tr>\n","      <th>d/p</th>\n","      <td>0.023451</td>\n","      <td>0.005185</td>\n","    </tr>\n","    <tr>\n","      <th>corpr</th>\n","      <td>0.011250</td>\n","      <td>0.006746</td>\n","    </tr>\n","    <tr>\n","      <th>e/p</th>\n","      <td>0.006753</td>\n","      <td>0.004698</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         Importance       std\n","Feature                      \n","d/y        0.025970  0.008850\n","d/p        0.023451  0.005185\n","corpr      0.011250  0.006746\n","e/p        0.006753  0.004698"]},"execution_count":175,"metadata":{},"output_type":"execute_result"}],"source":["\n","rs2all_avg = rs2base.imp['Importance'].mean()\n","print(f'mean of all FI scores: {all_avg:.4f}')\n","rs2base.imp[rs2base.imp['Importance'] > all_avg].sort_values(by='Importance', ascending=False)"]},{"cell_type":"markdown","metadata":{},"source":["## Question 6\n","\n","Retrain your RF model using the above-average features obtained in #5. Do any of the performance metrics improve over the Module 4 results? How do these metrics compare to those in #4 above? (16 points)\n","\n","| model                     |   precision_train |   recall_train |   f1_train |   auc_train |   precision_test |   recall_test |   f1_test |   auc_test |\n","|:--------------------------|------------------:|---------------:|-----------:|------------:|-----------------:|--------------:|----------:|-----------:|\n","| basemodel                  |          0.978593 |       0.963855 |   0.971168 |    0.96377  |         0.96988  |      0.964072 |  0.966967 |   0.955511 |\n","| feature_selected_model    |          0.990683 |       0.960843 |   0.975535 |    0.974152 |         0.975309 |      0.946108 |  0.960486 |   0.953464 |\n","| rs2base                   |          0.972477 |       0.957831 |   0.965099 |    0.955442 |         0.963415 |      0.946108 |  0.954683 |   0.942211 |\n","| rs2feature_selected_model |          0.979042 |       0.98494  |   0.981982 |    0.972859 |         0.975758 |      0.964072 |  0.96988  |   0.961178 |\n","\n","So with feature selection from Q5 feeding the rs2feature_selected_model we can see that against original model there is again a slight improvement in precision.  Recall actually stays the same. F1 has a very slight increase and auc-pr is up half a point in test.\n","\n","I think there's overall a slight increase in the metrics but with how unstable the MDA analysis is I don't think this can be conclusive. It would be interesting to see this test repliated with LIME & SHAP or 1000 iterations. The paper shows that the feature selection should result in a notable improvement when combined with high number of iterations for MDA or with LIME/SHAP.\n"]},{"cell_type":"code","execution_count":176,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["start MDA 2024-02-03 17:11:16.497124\n","   Split 1\n"]},{"name":"stdout","output_type":"stream","text":["   Split 2\n","   Split 3\n","   Split 4\n","   Split 5\n","   Split 6\n","   Split 7\n","   Split 8\n","   Split 9\n","   Split 10\n","end MDA 2024-02-03 17:11:21.083132\n"]}],"source":["rs2feature_selected = rfmodel('rs2feature_selected_model', \n","                                 combined[['d/y', 'd/p', 'corpr', 'e/p', 'target', 'date']], seed=1)\n","\n","rs2feature_selected.featImpMDA_classify()\n","rs2feature_selected.pred()\n","rs2feature_selected.getAccuracy()\n","\n","rs2base.pred()\n","rs2base.getAccuracy()\n","\n","rs2bigholder = []\n","mod2_list = [rs2base, rs2feature_selected]\n","\n","for newmod in mod2_list:\n","    smallholder = {}\n","    smallholder['model'] = newmod.name\n","    smallholder['precision_train'] = newmod.bigscoretrain[0]\n","    smallholder['recall_train'] = newmod.bigscoretrain[1]\n","    smallholder['f1_train'] = newmod.bigscoretrain[2]\n","    smallholder['auc_train'] = newmod.auc_train\n","    smallholder['precision_test'] = newmod.bigscoretest[0]\n","    smallholder['recall_test'] = newmod.bigscoretest[1]\n","    smallholder['f1_test'] = newmod.bigscoretest[2]\n","    smallholder['auc_test'] = newmod.auc_test\n","    rs2bigholder.append(smallholder)\n"]},{"cell_type":"code","execution_count":177,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>precision_train</th>\n","      <th>recall_train</th>\n","      <th>f1_train</th>\n","      <th>auc_train</th>\n","      <th>precision_test</th>\n","      <th>recall_test</th>\n","      <th>f1_test</th>\n","      <th>auc_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>rs2base</td>\n","      <td>0.972477</td>\n","      <td>0.957831</td>\n","      <td>0.965099</td>\n","      <td>0.955442</td>\n","      <td>0.963415</td>\n","      <td>0.946108</td>\n","      <td>0.954683</td>\n","      <td>0.942211</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>rs2feature_selected_model</td>\n","      <td>0.979042</td>\n","      <td>0.984940</td>\n","      <td>0.981982</td>\n","      <td>0.972859</td>\n","      <td>0.975758</td>\n","      <td>0.964072</td>\n","      <td>0.969880</td>\n","      <td>0.961178</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                       model  precision_train  recall_train  f1_train  \\\n","0                    rs2base         0.972477      0.957831  0.965099   \n","1  rs2feature_selected_model         0.979042      0.984940  0.981982   \n","\n","   auc_train  precision_test  recall_test   f1_test  auc_test  \n","0   0.955442        0.963415     0.946108  0.954683  0.942211  \n","1   0.972859        0.975758     0.964072  0.969880  0.961178  "]},"execution_count":177,"metadata":{},"output_type":"execute_result"}],"source":["rs2df = pd.DataFrame(rs2bigholder)\n","rs2df"]},{"cell_type":"code","execution_count":178,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>precision_train</th>\n","      <th>recall_train</th>\n","      <th>f1_train</th>\n","      <th>auc_train</th>\n","      <th>precision_test</th>\n","      <th>recall_test</th>\n","      <th>f1_test</th>\n","      <th>auc_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>basemodel</td>\n","      <td>0.978593</td>\n","      <td>0.963855</td>\n","      <td>0.971168</td>\n","      <td>0.963770</td>\n","      <td>0.969880</td>\n","      <td>0.964072</td>\n","      <td>0.966967</td>\n","      <td>0.955511</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>feature_selected_model</td>\n","      <td>0.990683</td>\n","      <td>0.960843</td>\n","      <td>0.975535</td>\n","      <td>0.974152</td>\n","      <td>0.975309</td>\n","      <td>0.946108</td>\n","      <td>0.960486</td>\n","      <td>0.953464</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>rs2base</td>\n","      <td>0.972477</td>\n","      <td>0.957831</td>\n","      <td>0.965099</td>\n","      <td>0.955442</td>\n","      <td>0.963415</td>\n","      <td>0.946108</td>\n","      <td>0.954683</td>\n","      <td>0.942211</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>rs2feature_selected_model</td>\n","      <td>0.979042</td>\n","      <td>0.984940</td>\n","      <td>0.981982</td>\n","      <td>0.972859</td>\n","      <td>0.975758</td>\n","      <td>0.964072</td>\n","      <td>0.969880</td>\n","      <td>0.961178</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                       model  precision_train  recall_train  f1_train  \\\n","0                  basemodel         0.978593      0.963855  0.971168   \n","1     feature_selected_model         0.990683      0.960843  0.975535   \n","0                    rs2base         0.972477      0.957831  0.965099   \n","1  rs2feature_selected_model         0.979042      0.984940  0.981982   \n","\n","   auc_train  precision_test  recall_test   f1_test  auc_test  \n","0   0.963770        0.969880     0.964072  0.966967  0.955511  \n","1   0.974152        0.975309     0.946108  0.960486  0.953464  \n","0   0.955442        0.963415     0.946108  0.954683  0.942211  \n","1   0.972859        0.975758     0.964072  0.969880  0.961178  "]},"execution_count":178,"metadata":{},"output_type":"execute_result"}],"source":["all_scores = pd.concat([scores_df, rs2df], axis=0)\n","all_scores"]},{"cell_type":"code","execution_count":179,"metadata":{},"outputs":[{"data":{"text/plain":["'| model                     |   precision_train |   recall_train |   f1_train |   auc_train |   precision_test |   recall_test |   f1_test |   auc_test |\\n|:--------------------------|------------------:|---------------:|-----------:|------------:|-----------------:|--------------:|----------:|-----------:|\\n| basemodel                 |          0.978593 |       0.963855 |   0.971168 |    0.96377  |         0.96988  |      0.964072 |  0.966967 |   0.955511 |\\n| feature_selected_model    |          0.990683 |       0.960843 |   0.975535 |    0.974152 |         0.975309 |      0.946108 |  0.960486 |   0.953464 |\\n| rs2base                   |          0.972477 |       0.957831 |   0.965099 |    0.955442 |         0.963415 |      0.946108 |  0.954683 |   0.942211 |\\n| rs2feature_selected_model |          0.979042 |       0.98494  |   0.981982 |    0.972859 |         0.975758 |      0.964072 |  0.96988  |   0.961178 |'"]},"execution_count":179,"metadata":{},"output_type":"execute_result"}],"source":["all_scores.to_markdown(index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"}},"nbformat":4,"nbformat_minor":1}
