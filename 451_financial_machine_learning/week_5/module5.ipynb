{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as mpl\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import multiprocessing as mp\n",
    "import datetime as dt\n",
    "import sys\n",
    "from sklearn.model_selection._split import _BaseKFold\n",
    "from pathlib import PurePath, Path\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#already tranbsformed data from module 4\n",
    "monthly_final = pd.read_csv('monthly_data.csv')\n",
    "quarterly_final = pd.read_csv('quarterly_data.csv')\n",
    "yearly_final = pd.read_csv('yearly_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featImpMDI(fit, featnames):\n",
    "    # Mean Decrease Impurity feature importance\n",
    "    df0 = {i:tree.feature_importances_ for i, tree in enumerate(fit.estimators_)}\n",
    "    df0 = pd.DataFrame.from_dict(df0, orient='index')\n",
    "    df0.columns = featnames\n",
    "    df0 = df0.replace(0, np.nan)  # because max_features = 1\n",
    "    imp = pd.concat({'mean': df0.mean(), 'std': df0.std() * df0.shape[0]**-.5}, axis=1)\n",
    "    imp /= imp['mean'].sum()\n",
    "    return imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVol(close,span0=100):\n",
    "    # daily vol reindexed to close\n",
    "    df0=close.index.searchsorted(close.index-1)\n",
    "    #bp()\n",
    "    df0=df0[df0>0]\n",
    "    #bp()\n",
    "    df0=(pd.Series(close.index[df0-1],\n",
    "                   index=close.index[close.shape[0]-df0.shape[0]:]))\n",
    "    #bp()\n",
    "    try:\n",
    "        df0=close.loc[df0.index]/close.loc[df0.values].values-1 # daily rets\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('adjusting shape of close.loc[df0.index]')\n",
    "        cut = close.loc[df0.index].shape[0] - close.loc[df0.values].shape[0]\n",
    "        df0=close.loc[df0.index].iloc[:-cut]/close.loc[df0.values].values-1\n",
    "    df0=df0.ewm(span=span0).std().rename('dailyVol')\n",
    "    return df0\n",
    "\n",
    "\n",
    "def applyPtSlOnT1(close,events,ptSl,molecule):\n",
    "    # apply stop loss/profit taking, if it takes place before t1 (end of event)\n",
    "    events_=events.loc[molecule]\n",
    "    out=events_[['t1']].copy(deep=True)\n",
    "    if ptSl[0]>0: pt=ptSl[0]*events_['trgt']\n",
    "    else: pt=pd.Series(index=events.index) # NaNs\n",
    "    if ptSl[1]>0: sl=-ptSl[1]*events_['trgt']\n",
    "    else: sl=pd.Series(index=events.index) # NaNs\n",
    "    for loc,t1 in events_['t1'].fillna(close.index[-1]).iteritems():\n",
    "        df0=close[loc:t1] # path prices\n",
    "        df0=(df0/close[loc]-1)*events_.at[loc,'side'] # path returns\n",
    "        out.loc[loc,'sl']=df0[df0<sl[loc]].index.min() # earliest stop loss\n",
    "        out.loc[loc,'pt']=df0[df0>pt[loc]].index.min() # earliest profit taking\n",
    "    return out\n",
    "# =======================================================\n",
    "# Gettting Time of First Touch (getEvents) [3.3]\n",
    "def getEvents(close, tEvents, ptSl, trgt, minRet, numThreads,t1=False, side=None):\n",
    "    #1) get target\n",
    "    trgt=trgt.loc[tEvents]\n",
    "    trgt=trgt[trgt>minRet] # minRet\n",
    "    #2) get t1 (max holding period)\n",
    "    if t1 is False:t1=pd.Series(pd.NaT, index=tEvents)\n",
    "    #3) form events object, apply stop loss on t1\n",
    "    if side is None:side_,ptSl_=pd.Series(1.,index=trgt.index), [ptSl[0],ptSl[0]]\n",
    "    else: side_,ptSl_=side.loc[trgt.index],ptSl[:2]\n",
    "    events=(pd.concat({'t1':t1,'trgt':trgt,'side':side_}, axis=1)\n",
    "            .dropna(subset=['trgt']))\n",
    "    df0=mpPandasObj(func=applyPtSlOnT1,pdObj=('molecule',events.index),\n",
    "                    numThreads=numThreads,close=close,events=events,\n",
    "                    ptSl=ptSl_)\n",
    "    events['t1']=df0.dropna(how='all').min(axis=1) #pd.min ignores nan\n",
    "    if side is None:events=events.drop('side',axis=1)\n",
    "    return events\n",
    "# =======================================================\n",
    "# Adding Vertical Barrier [3.4]\n",
    "def addVerticalBarrier(tEvents, close, numDays=1):\n",
    "    t1=close.index.searchsorted(tEvents+pd.Timedelta(days=numDays))\n",
    "    t1=t1[t1<close.shape[0]]\n",
    "    t1=(pd.Series(close.index[t1],index=tEvents[:t1.shape[0]]))\n",
    "    return t1\n",
    "\n",
    "# =======================================================\n",
    "# Labeling for side and size [3.5, 3.8]\n",
    "\n",
    "\n",
    "def getBins(events, close, t1=None):\n",
    "    '''\n",
    "    Compute event's outcome (including side information, if provided).\n",
    "    events is a DataFrame where:\n",
    "    -events.index is event's starttime\n",
    "    -events['t1'] is event's endtime\n",
    "    -events['trgt'] is event's target\n",
    "    -events['side'] (optional) implies the algo's position side\n",
    "    -t1 is original vertical barrier series\n",
    "    Case 1: ('side' not in events): bin in (-1,1) <-label by price action\n",
    "    Case 2: ('side' in events): bin in (0,1) <-label by pnl (meta-labeling)\n",
    "    '''\n",
    "    # 1) prices aligned with events\n",
    "    events_ = events.dropna(subset=['t1'])\n",
    "    px = events_.index.union(events_['t1'].values).drop_duplicates()\n",
    "    px = close.reindex(px, method='bfill')\n",
    "    # 2) create out object\n",
    "    out = pd.DataFrame(index=events_.index)\n",
    "    out['ret'] = px.loc[events_['t1'].values].values / px.loc[\n",
    "        events_.index] - 1\n",
    "    if 'side' in events_: out['ret'] *= events_['side']  # meta-labeling\n",
    "    out['bin'] = np.sign(out['ret'])\n",
    "\n",
    "    if 'side' not in events_:\n",
    "        # only applies when not meta-labeling.\n",
    "        # to update bin to 0 when vertical barrier is touched, we need the\n",
    "        # original vertical barrier series since the events['t1'] is the time\n",
    "        # of first touch of any barrier and not the vertical barrier\n",
    "        # specifically. The index of the intersection of the vertical barrier\n",
    "        # values and the events['t1'] values indicate which bin labels needs\n",
    "        # to be turned to 0.\n",
    "        vtouch_first_idx = events[events['t1'].isin(t1.values)].index\n",
    "        out.loc[vtouch_first_idx, 'bin'] = 0.\n",
    "\n",
    "    if 'side' in events_: out.loc[out['ret'] <= 0, 'bin'] = 0  # meta-labeling\n",
    "    return out\n",
    "# =======================================================\n",
    "# Expanding getBins to Incorporate Meta-Labeling [3.7]\n",
    "def getBinsOld(events, close):\n",
    "    '''\n",
    "    Compute event's outcome (including side information, if provided).\n",
    "    events is a DataFrame where:\n",
    "    -events.index is event's starttime\n",
    "    -events['t1'] is event's endtime\n",
    "    -events['trgt'] is event's target\n",
    "    -events['side'] (optional) implies the algo's position side\n",
    "    Case 1: ('side' not in events): bin in (-1,1) <-label by price action\n",
    "    Case 2: ('side' in events): bin in (0,1) <-label by pnl (meta-labeling)\n",
    "    '''\n",
    "    #1) prices aligned with events\n",
    "    events_=events.dropna(subset=['t1'])\n",
    "    px=events_.index.union(events_['t1'].values).drop_duplicates()\n",
    "    px=close.reindex(px,method='bfill')\n",
    "    #2) create out object\n",
    "    out=pd.DataFrame(index=events_.index)\n",
    "    out['ret']=px.loc[events_['t1'].values].values/px.loc[events_.index]-1\n",
    "    if 'side' in events_:out['ret']*=events_['side'] # meta-labeling\n",
    "    out['bin']=np.sign(out['ret'])\n",
    "    if 'side' in events_:out.loc[out['ret']<=0,'bin']=0 # meta-labeling\n",
    "    return out\n",
    "# =======================================================\n",
    "# Dropping Unnecessary Labels [3.8]\n",
    "def dropLabels(events, minPct=.05):\n",
    "    # apply weights, drop labels with insufficient examples\n",
    "    while True:\n",
    "        df0=events['bin'].value_counts(normalize=True)\n",
    "        if df0.min()>minPct or df0.shape[0]<3:break\n",
    "        print('dropped label: ', df0.argmin(),df0.min())\n",
    "        events=events[events['bin']!=df0.argmin()]\n",
    "    return events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PurgedKFold(_BaseKFold):\n",
    "    \"\"\"\n",
    "    Extend KFold class to work with labels that span intervals\n",
    "    The train is purged of observations overlapping test-label intervals\n",
    "    Test set is assumed contiguous (shuffle=False), w/o training samples in between\n",
    "    \"\"\"\n",
    "    def __init__(self,n_splits=3,t1=None,pctEmbargo=0.):\n",
    "        if not isinstance(t1,pd.Series):\n",
    "            raise ValueError('Label Through Dates must be a pd.Series')\n",
    "        super(PurgedKFold,self).__init__(n_splits,shuffle=False,random_state=None)\n",
    "        self.t1=t1\n",
    "        self.pctEmbargo=pctEmbargo\n",
    "        \n",
    "    def split(self,X,y=None,groups=None):\n",
    "        if (X.index==self.t1.index).sum()!=len(self.t1):\n",
    "            raise ValueError('X and ThruDateValues must have the same index')\n",
    "        indices=np.arange(X.shape[0])\n",
    "        mbrg=int(X.shape[0]*self.pctEmbargo)\n",
    "        test_starts=[\n",
    "            (i[0],i[-1]+1) for i in np.array_split(np.arange(X.shape[0]),\n",
    "                                                   self.n_splits)\n",
    "        ]\n",
    "        for i,j in test_starts:\n",
    "            t0=self.t1.index[i] # start of test set\n",
    "            test_indices=indices[i:j]\n",
    "            maxT1Idx=self.t1.index.searchsorted(self.t1[test_indices].max())\n",
    "            train_indices=self.t1.index.searchsorted(self.t1[self.t1<=t0].index)\n",
    "            if maxT1Idx<X.shape[0]: # right train ( with embargo)\n",
    "                train_indices=np.concatenate((train_indices, indices[maxT1Idx+mbrg:]))\n",
    "            yield train_indices,test_indices\n",
    "\n",
    "\n",
    "def featImpMDA(clf,X,y,cv,sample_weight,t1,pctEmbargo,scoring='neg_log_loss'):\n",
    "    # feat imporant based on OOS score reduction\n",
    "    if scoring not in ['neg_log_loss','accuracy']:\n",
    "        raise ValueError('wrong scoring method.')\n",
    "    from sklearn.metrics import log_loss, accuracy_score\n",
    "    cvGen=PurgedKFold(n_splits=cv,t1=t1,pctEmbargo=pctEmbargo) # purged cv\n",
    "    scr0,scr1=pd.SEries(), pd.DataFrame(columns=X.columns)\n",
    "\n",
    "    for i,(train,test) in enumerate(cvGen.split(X=X)):\n",
    "        X0,y0,w0=X.iloc[train,:],y.iloc[train],sample_weight.iloc[train]\n",
    "        X1,y1,w1=X.iloc[test,:],y.iloc[test],sample_weight.iloc[test]\n",
    "        fit=clf.fit(X=X0,y=y0,sample_weight=w0.values)\n",
    "        if scoring=='neg_log_loss':\n",
    "            prob=fit.predict_proba(X1)\n",
    "            scr0.loc[i]=-log_loss(y1,prob,sample_weight=w1.values,\n",
    "                                  labels=clf.classes_)\n",
    "        else:\n",
    "            pred=fit.predict(X1)\n",
    "            scr0.loc[i]=accuracy_score(y1,pred,sample_weight=w1.values)\n",
    "\n",
    "    for j in X.columns:\n",
    "        X1_=X1.copy(deep=True)\n",
    "        np.random.shuffle(X1_[j].values) # permutation of a single column\n",
    "        if scoring=='neg_log_loss':\n",
    "            prob=fit.predict_proba(X1_)\n",
    "            scr1.loc[i,j]=-log_loss(y1,prob,sample_weight=w1.values,\n",
    "                                    labels=clf.classes_)\n",
    "        else:\n",
    "            pred=fit.predict(X1_)\n",
    "            scr1.loc[i,j]=accuracy_score(y1,pred,sample_weight=w1.values)\n",
    "    imp=(-scr1).add(scr0,axis=0)\n",
    "    if scoring=='neg_log_loss':imp=imp/-scr1\n",
    "    else: imp=imp/(1.-scr1)\n",
    "    imp=(pd.concat({'mean':imp.mean(),\n",
    "                    'std':imp.std()*imp.shape[0]**-0.5},\n",
    "                   axis=1))\n",
    "    return imp,scr0.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auxFeatImpSFI(featNames, clf, trnsX, cont, scoring, cvGen):\n",
    "    imp = pd.DataFrame(columns=['mean', 'std'])\n",
    "    for featname in featNames:\n",
    "        df0=cvScore(clf, X=trnsX[['featName']], y=cont['bin'], sample_weight=cont['w'], scoring=scoring, cvGen=cvGen)\n",
    "        imp.loc['mean', featname]=df0.mean()\n",
    "        imp.loc['std', featname]=df0.std()*df0.shape[0]**-.5\n",
    "    return imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eVec(dot,varThres):\n",
    "    # compute eVec from dot proc matrix, reduce dimension\n",
    "    eVal,eVec=np.linalg.eigh(dot)\n",
    "    idx=eVal.argsort()[::-1] # arugments for sorting eVal desc.\n",
    "    eVal,eVec=eVal[idx],eVec[:,idx]\n",
    "    #2) only positive eVals\n",
    "    eVal=(pd.Series(eVal,index=['PC_'+str(i+1)\n",
    "                                for i in range(eVal.shape[0])]))\n",
    "    eVec=(pd.DataFrame(eVec,index=dot.index,columns=eVal.index))\n",
    "    eVec=eVec.loc[:,eVal.index]\n",
    "    #3) reduce dimension, form PCs\n",
    "    cumVar=eVal.cumsum()/eVal.sum()\n",
    "    dim=cumVar.values.searchsorted(varThres)\n",
    "    eVal,eVec=eVal.iloc[:dim+1],eVec.iloc[:,:dim+1]\n",
    "    return eVal,eVec\n",
    "\n",
    "def orthoFeats(dfx,varThres=0.95):\n",
    "    # given a DataFrame, dfx, of features, compute orthofeatures dfP\n",
    "    dfZ=dfx.sub(dfx.mean(),axis=1).div(dfx.std(),axis=1) # standardize\n",
    "    dot=(pd.DataFrame(np.dot(dfZ.T,dfZ),\n",
    "                      index=dfx.columns,\n",
    "                      columns=dfx.columns))\n",
    "    eVal,eVec=get_eVec(dot,varThres)\n",
    "    dfP=np.dot(dfZ,eVec)\n",
    "    return dfP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvScore(clf,X,y,sample_weight,scoring='neg_log_loss',\n",
    "            t1=None,cv=None,cvGen=None,pctEmbargo=None):\n",
    "    if scoring not in ['neg_log_loss','accuracy']:\n",
    "        raise Exception('wrong scoring method.')\n",
    "    from sklearn.metrics import log_loss,accuracy_score\n",
    "    idx = pd.IndexSlice\n",
    "    if cvGen is None:\n",
    "        cvGen=PurgedKFold(n_splits=cv,t1=t1,pctEmbargo=pctEmbargo) # purged\n",
    "    score=[]\n",
    "    for train,test in cvGen.split(X=X):\n",
    "        fit=clf.fit(X=X.iloc[idx[train],:],y=y.iloc[idx[train]],\n",
    "                    sample_weight=sample_weight.iloc[idx[train]].values)\n",
    "        if scoring=='neg_log_loss':\n",
    "            prob=fit.predict_proba(X.iloc[idx[test],:])\n",
    "            score_=-log_loss(y.iloc[idx[test]], prob,\n",
    "                             sample_weight=sample_weight.iloc[idx[test]].values,\n",
    "                             labels=clf.classes_)\n",
    "        else:\n",
    "            pred=fit.predict(X.iloc[idx[test],:])\n",
    "            score_=accuracy_score(y.iloc[idx[test]],pred,\n",
    "                                  sample_weight=sample_weight.iloc[idx[test]].values)\n",
    "        score.append(score_)\n",
    "    return np.array(score)\n",
    "\n",
    "def auxFeatImpSFI(featNames, clf, trnsX, cont, scoring, cvGen):\n",
    "    imp = pd.DataFrame(columns=['mean', 'std'])\n",
    "    for featname in featNames:\n",
    "        df0=cvScore(clf, X=trnsX[['featName']], y=cont['bin'], sample_weight=cont['w'], scoring=scoring, cvGen=cvGen)\n",
    "        imp.loc['mean', featname]=df0.mean()\n",
    "        imp.loc['std', featname]=df0.std()*df0.shape[0]**-.5\n",
    "    return imp\n",
    "\n",
    "def expandCall(kargs):\n",
    "    # Expand the arguments of a callback function, kargs['func']\n",
    "    func=kargs['func']\n",
    "    del kargs['func']\n",
    "    out=func(**kargs)\n",
    "    return out\n",
    "\n",
    "def reportProgress(jobNum,numJobs,time0,task):\n",
    "    # Report progress as asynch jobs are completed\n",
    "    msg=[float(jobNum)/numJobs, (time.time()-time0)/60.]\n",
    "    msg.append(msg[1]*(1/msg[0]-1))\n",
    "    timeStamp=str(dt.datetime.fromtimestamp(time.time()))\n",
    "    msg=timeStamp+' '+str(round(msg[0]*100,2))+'% '+task+' done after '+ \\\n",
    "        str(round(msg[1],2))+' minutes. Remaining '+str(round(msg[2],2))+' minutes.'\n",
    "    if jobNum<numJobs:sys.stderr.write(msg+'\\r')\n",
    "    else:sys.stderr.write(msg+'\\n')\n",
    "    return\n",
    "\n",
    "def processJobs_(jobs):\n",
    "    # Run jobs sequentially, for debugging\n",
    "    out=[]\n",
    "    for job in jobs:\n",
    "        out_=expandCall(job)\n",
    "        out.append(out_)\n",
    "    return out\n",
    "\n",
    "\n",
    "def processJobs(jobs,task=None,numThreads=24):\n",
    "    # Run in parallel.\n",
    "    # jobs must contain a 'func' callback, for expandCall\n",
    "    if task is None:task=jobs[0]['func'].__name__\n",
    "    pool=mp.Pool(processes=numThreads)\n",
    "    outputs,out,time0=pool.imap_unordered(expandCall,jobs),[],time.time()\n",
    "    # Process asyn output, report progress\n",
    "    for i,out_ in enumerate(outputs,1):\n",
    "        out.append(out_)\n",
    "        reportProgress(i,len(jobs),time0,task)\n",
    "    pool.close();pool.join() # this is needed to prevent memory leaks\n",
    "    return out\n",
    "\n",
    "def linParts(numAtoms,numThreads):\n",
    "    # partition of atoms with a single loop\n",
    "    parts=np.linspace(0,numAtoms,min(numThreads,numAtoms)+1)\n",
    "    parts=np.ceil(parts).astype(int)\n",
    "    return parts\n",
    "\n",
    "def nestedParts(numAtoms,numThreads,upperTriang=False):\n",
    "    # partition of atoms with an inner loop\n",
    "    parts,numThreads_=[0],min(numThreads,numAtoms)\n",
    "    for num in range(numThreads_):\n",
    "        part=1+4*(parts[-1]**2+parts[-1]+numAtoms*(numAtoms+1.)/numThreads_)\n",
    "        part=(-1+part**.5)/2.\n",
    "        parts.append(part)\n",
    "    parts=np.round(parts).astype(int)\n",
    "    if upperTriang: # the first rows are heaviest\n",
    "        parts=np.cumsum(np.diff(parts)[::-1])\n",
    "        parts=np.append(np.array([0]),parts)\n",
    "    return parts\n",
    "\n",
    "def mpPandasObj(func,pdObj,numThreads=24,mpBatches=1,linMols=True,**kargs):\n",
    "    '''\n",
    "    Parallelize jobs, return a dataframe or series\n",
    "    + func: function to be parallelized. Returns a DataFrame\n",
    "    + pdObj[0]: Name of argument used to pass the molecule\n",
    "    + pdObj[1]: List of atoms that will be grouped into molecules\n",
    "    + kwds: any other argument needed by func\n",
    "\n",
    "    Example: df1=mpPandasObj(func,('molecule',df0.index),24,**kwds)\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    #if linMols:parts=linParts(len(argList[1]),numThreads*mpBatches)\n",
    "    #else:parts=nestedParts(len(argList[1]),numThreads*mpBatches)\n",
    "    if linMols:parts=linParts(len(pdObj[1]),numThreads*mpBatches)\n",
    "    else:parts=nestedParts(len(pdObj[1]),numThreads*mpBatches)\n",
    "\n",
    "    jobs=[]\n",
    "    for i in range(1,len(parts)):\n",
    "        job={pdObj[0]:pdObj[1][parts[i-1]:parts[i]],'func':func}\n",
    "        job.update(kargs)\n",
    "        jobs.append(job)\n",
    "    if numThreads==1:out=processJobs_(jobs)\n",
    "    else: out=processJobs(jobs,numThreads=numThreads)\n",
    "    if isinstance(out[0],pd.DataFrame):df0=pd.DataFrame()\n",
    "    elif isinstance(out[0],pd.Series):df0=pd.Series()\n",
    "    else:return out\n",
    "    for i in out:df0=df0.append(i)\n",
    "    df0=df0.sort_index()\n",
    "    return df0\n",
    "\n",
    "def featImportances(trnsX,cont,n_estimators=1000,cv=10,\n",
    "                    max_samples=1.,numThreads=11,pctEmbargo=0,\n",
    "                    scoring='accuracy',method='SFI',minWLeaf=0.,**kargs):\n",
    "    # feature importance from a random forest\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import BaggingClassifier\n",
    "    #from mpEngine import mpPandasObj\n",
    "    n_jobs=(-1 if numThreads>1 else 1) # run 1 thread w/ ht_helper in dirac1\n",
    "    #1) prepare classifier,cv. max_features=1, to prevent masking\n",
    "    clf=DecisionTreeClassifier(criterion='entropy',max_features=1,\n",
    "                               class_weight='balanced',\n",
    "                               min_weight_fraction_leaf=minWLeaf)\n",
    "    clf=BaggingClassifier(base_estimator=clf,n_estimators=n_estimators,\n",
    "                          max_features=1.,max_samples=max_samples,\n",
    "                          oob_score=True,n_jobs=n_jobs)\n",
    "    fit=clf.fit(X=trnsX,y=cont['target'],sample_weight=cont['w'].values)\n",
    "    oob=fit.oob_score_\n",
    "    if method=='MDI':\n",
    "        imp=featImpMDI(fit,featNames=trnsX.columns)\n",
    "        oos=cvScore(clf,X=trnsX,y=cont['bin'],cv=cv,sample_weight=cont['w'],\n",
    "                    t1=cont['t1'],pctEmbargo=pctEmbargo,scoring=scoring).mean()\n",
    "    elif method=='MDA':\n",
    "        imp,oos=featImpMDA(clf,X=trnsX,y=cont['bin'],cv=cv,\n",
    "                           sample_weight=cont['w'],t1=cont['t1'],\n",
    "                           pctEmbargo=pctEmbargo,scoring=scoring)\n",
    "    elif method=='SFI':\n",
    "        cvGen=PurgedKFold(n_splits=cv,t1=cont['t1'],pctEmbargo=pctEmbargo)\n",
    "        oos=cvScore(clf,X=trnsX,y=cont['bin'],sample_weight=cont['w'],\n",
    "                    scoring=scoring,cvGen=cvGen).mean()\n",
    "        clf.n_jobs=1 # parallelize auxFeatImpSFI rather than clf\n",
    "        imp=mpPandasObj(auxFeatImpSFI,('featNames',trnsX.columns),numThreads,\n",
    "                        clf=clf,trnsX=trnsX,cont=cont,scoring=scoring,cvGen=cvGen)\n",
    "    return imp,oob,oos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotFeatImportance(pathOut,imp,oob,oos,method,tag=0,simNum=0,**kargs):\n",
    "    # plot mean imp bars with std\n",
    "    mpl.figure(figsize=(10,imp.shape[0]/5.))\n",
    "    imp=imp.sort_values('mean',ascending=True)\n",
    "    ax=imp['mean'].plot(kind='barh',color='b',alpha=0.25,xerr=imp['std'],\n",
    "                        error_kw={'ecolor':'r'})\n",
    "    if method=='MDI':\n",
    "        mpl.xlim([0,imp.sum(axis=1).max()])\n",
    "        mpl.axvline(1./imp.shape[0],lw=1.,color='r',ls='dotted')\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    for i,j in zip(ax.patches,imp.index):\n",
    "        ax.text(i.get_width()/2, i.get_y()+i.get_height()/2,\n",
    "                j,ha='center',va='center',color='k')\n",
    "    mpl.title('tag='+tag+' | simNUm='+str(simNum)+' | oob='+str(round(oob,4))+' | oos='+str(round(oos,4)))\n",
    "    mpl.savefig(pathOut+'featImportance_'+str(simNum)+'.png',dpi=100)\n",
    "    mpl.clf();mpl.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theFunc(df_, n_features=40,n_informative=10,n_redundant=10,n_estimators=1000,\n",
    "             n_samples=10000,cv=10):\n",
    "    # test the performance of the feat importance functions on artificial data\n",
    "    # Nr noise features = n_featurs-n_informative-n_redundant\n",
    "    trnsX,cont = df_.drop('target', axis=1),df_[['target']]\n",
    "    dict0={'minWLeaf':[0.],'scoring':['accuracy'],'method':['MDI','MDA','SFI'],\n",
    "           'max_samples':[1.]}\n",
    "    jobs,out=(dict(zip(dict0,i))for i in product(*dict0.values())),[]\n",
    "    kargs={'n_estimators':n_estimators,'tag':'testFunc','cv':cv}\n",
    "    for job in jobs:\n",
    "        job['simNum']=job['method']+'_'+job['scoring']+'_'+'%.2f'%job['minWLeaf']+\\\n",
    "        '_'+str(job['max_samples'])\n",
    "        print(job['simNum'])\n",
    "        kargs.update(job)\n",
    "        imp,oob,oos=featImportances(trnsX=trnsX,cont=cont,**kargs)\n",
    "        plotFeatImportance(imp=imp,oob=oob,oos=oos,**kargs)\n",
    "        df0=imp[['mean']]/imp['mean'].abs().sum()\n",
    "        df0['type']=[i[0] for i in df0.index]\n",
    "        df0=df0.groupby('type')['mean'].abs().sum()\n",
    "        df0.update({'oob':oob,'oos':oos});df0.update(job)\n",
    "        out.append(df0)\n",
    "    out=(pd.DataFrame(out).sort_values(['method','scoring','minWLeaf','max_samples']))\n",
    "    out=out['method','scoring','minWLeaf','max_samples','I','R','N','oob','oos']\n",
    "    #out.to_csv(kargs['pathOut']+'stats.csv')\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the random seed to 1, and using the same dataset as in the Module 4 assignment Download the same dataset as in the Module 4 assignment, compute the feature importance scores of each feature by applying the featImportance function (Snippet 8.8 in AFML) on the 10 cross validation sets within the train set defined there.\n",
    "\n",
    " Why can’t FS be applied to the train set as a whole? (For a hint, please read assetCode with MDA using random dataLinks to an external site..) (16 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'Index', 'D12', 'E12', 'b/m', 'tbl', 'AAA', 'BAA', 'lty',\n",
       "       'ntis', 'Rfree', 'infl', 'ltr', 'corpr', 'svar', 'csp', 'CRSP_SPvw',\n",
       "       'CRSP_SPvwx', 'dp', 'dy', 'ep', 'ep10', 'de', 'dfy', 'tms', 'dfr',\n",
       "       'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out['w'] *= out.shape[0] / out['w'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDI_accuracy_0.00_1.0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'w'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\tkkim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'w'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m month_output \u001b[38;5;241m=\u001b[39m \u001b[43mtheFunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonthly_final\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[45], line 15\u001b[0m, in \u001b[0;36mtheFunc\u001b[1;34m(df_, n_features, n_informative, n_redundant, n_estimators, n_samples, cv)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(job[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimNum\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     14\u001b[0m kargs\u001b[38;5;241m.\u001b[39mupdate(job)\n\u001b[1;32m---> 15\u001b[0m imp,oob,oos\u001b[38;5;241m=\u001b[39m\u001b[43mfeatImportances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrnsX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrnsX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcont\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcont\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m plotFeatImportance(imp\u001b[38;5;241m=\u001b[39mimp,oob\u001b[38;5;241m=\u001b[39moob,oos\u001b[38;5;241m=\u001b[39moos,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkargs)\n\u001b[0;32m     17\u001b[0m df0\u001b[38;5;241m=\u001b[39mimp[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m/\u001b[39mimp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39msum()\n",
      "Cell \u001b[1;32mIn[43], line 137\u001b[0m, in \u001b[0;36mfeatImportances\u001b[1;34m(trnsX, cont, n_estimators, cv, max_samples, numThreads, pctEmbargo, scoring, method, minWLeaf, **kargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m clf\u001b[38;5;241m=\u001b[39mDecisionTreeClassifier(criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    132\u001b[0m                            class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    133\u001b[0m                            min_weight_fraction_leaf\u001b[38;5;241m=\u001b[39mminWLeaf)\n\u001b[0;32m    134\u001b[0m clf\u001b[38;5;241m=\u001b[39mBaggingClassifier(base_estimator\u001b[38;5;241m=\u001b[39mclf,n_estimators\u001b[38;5;241m=\u001b[39mn_estimators,\n\u001b[0;32m    135\u001b[0m                       max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m,max_samples\u001b[38;5;241m=\u001b[39mmax_samples,\n\u001b[0;32m    136\u001b[0m                       oob_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,n_jobs\u001b[38;5;241m=\u001b[39mn_jobs)\n\u001b[1;32m--> 137\u001b[0m fit\u001b[38;5;241m=\u001b[39mclf\u001b[38;5;241m.\u001b[39mfit(X\u001b[38;5;241m=\u001b[39mtrnsX,y\u001b[38;5;241m=\u001b[39mcont[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m],sample_weight\u001b[38;5;241m=\u001b[39m\u001b[43mcont\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m    138\u001b[0m oob\u001b[38;5;241m=\u001b[39mfit\u001b[38;5;241m.\u001b[39moob_score_\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMDI\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\tkkim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\tkkim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'w'"
     ]
    }
   ],
   "source": [
    "month_output = theFunc(monthly_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
