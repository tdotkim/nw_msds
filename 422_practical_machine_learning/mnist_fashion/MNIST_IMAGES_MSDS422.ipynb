{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXIJ15fwrqPd"
      },
      "source": [
        "# MNIST Fashion - TF"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PlrOQOyfrumq"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pVGSs_HVrZfY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import sklearn.metrics as metrics\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GUzY1n58sbYC"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist # 28x28 Fashion Image Data\n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot' ]\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jRYBlbgMsub9"
      },
      "source": [
        "## Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ltMnTEnswX5",
        "outputId": "1800db0c-c717-4880-e500-b79623d3f347"
      },
      "outputs": [],
      "source": [
        "# load the data into train/test split\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = tf.keras.utils.normalize( x_train, axis=1 )\n",
        "x_test = tf.keras.utils.normalize( x_test, axis=1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C82JEXhKtUyj",
        "outputId": "c52729cd-2ec7-43ec-8a4a-0a01988fd9a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape =  (28, 28)\n",
            "TOTAL SIZE =  784\n"
          ]
        }
      ],
      "source": [
        "# save the image shape\n",
        "# 28 by 28 pixels = 784 pixels\n",
        "input_shape = x_train[0].shape\n",
        "print(\"Shape = \", input_shape )\n",
        "\n",
        "total_size = input_shape[0] * input_shape[1]\n",
        "print(\"TOTAL SIZE = \", total_size)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "i5O5oymFt7vv"
      },
      "source": [
        "## Preview of an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fadNCpyut92J"
      },
      "outputs": [],
      "source": [
        "def getRandomIndex( DATA ) :\n",
        "    return random.randint(0, DATA.shape[0] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "nWb8Qczyt-ox",
        "outputId": "074fb93c-8dfb-4eae-a41e-047cad396f44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "who = 7838\n",
            "classed as = Trouser\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x1a6d0f72e80>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "who=0\n",
        "who=getRandomIndex( x_train )\n",
        "\n",
        "print(\"who =\", who)\n",
        "\n",
        "print(\"classed as =\", class_names[y_train[who]])\n",
        "#print( x_train[who])\n",
        "plt.imshow(x_train[who], plt.cm.binary) \n",
        "#plt.imshow(x_train[who] ) \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lEYLseHxvGm3"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TNCUGK69vJcC"
      },
      "source": [
        "### Flatten the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExANjDtyvI6k",
        "outputId": "12de7046-5fd2-4b40-a1b3-72c56ba1acd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000, 784)\n"
          ]
        }
      ],
      "source": [
        "new_x_train = []\n",
        "for i in x_train :\n",
        "    new_x_train.append( i.flatten() )\n",
        "new_x_train = np.array( new_x_train )\n",
        "\n",
        "new_x_test = []\n",
        "for i in x_test :\n",
        "    new_x_test.append( i.flatten() )\n",
        "new_x_test = np.array( new_x_test )\n",
        "\n",
        "print( x_train.shape )\n",
        "print( new_x_train.shape )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "i9rpw2_4vqk2"
      },
      "source": [
        "### Fit the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VixvhJhhvtBB",
        "outputId": "caa8095f-2f4e-45c9-c741-c3a66c47b2a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Execution Time In Seconds =  2649.0\n",
            "Execution Time In Minutes =  44.1\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "theTrees = int( 2*total_size )\n",
        "\n",
        "clf = RandomForestClassifier( n_estimators = theTrees )\n",
        "clf.fit( new_x_train, y_train )\n",
        "\n",
        "Time_In_Seconds = round( time.time()-start_time, 0 )\n",
        "Time_In_Minutes = round( Time_In_Seconds / 60, 1 )\n",
        "print(\"Execution Time In Seconds = \", Time_In_Seconds )\n",
        "print(\"Execution Time In Minutes = \", Time_In_Minutes )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tY8KoJ_H605m",
        "outputId": "c3ed47b1-ae9f-4575-8333-72f411a63d85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9\n",
            "train accuracy 1.0\n",
            "9\n",
            "test accuracy 0.8799\n"
          ]
        }
      ],
      "source": [
        "pred_train = clf.predict( new_x_train )\n",
        "print( pred_train[0] )\n",
        "RF_acc_train = metrics.accuracy_score(y_train, pred_train )\n",
        "print( \"train accuracy\", RF_acc_train )\n",
        "\n",
        "pred_test = clf.predict( new_x_test )\n",
        "print( pred_test[0] )\n",
        "RF_acc = metrics.accuracy_score(y_test, pred_test )\n",
        "print( \"test accuracy\", RF_acc )\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ct5u1rm8Ai6U"
      },
      "source": [
        "## Log Model Attempt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "Iq-ZaECi7Rzx",
        "outputId": "08a528f0-3edf-42d6-cb13-0178ba6e98dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\TK\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logmodel = LogisticRegression()\n",
        "logmodel.fit( new_x_train, y_train )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRKMr6m874g3",
        "outputId": "cdfa3b71-d9f0-4df7-c8a0-62c91acb3e4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9\n",
            "train accuracy 0.8721333333333333\n",
            "9\n",
            "test accuracy 0.8528\n"
          ]
        }
      ],
      "source": [
        "log_pred_train = logmodel.predict( new_x_train )\n",
        "print( log_pred_train[0] )\n",
        "log_acc_train = metrics.accuracy_score(y_train, log_pred_train )\n",
        "print( \"train accuracy\", log_acc_train )\n",
        "\n",
        "log_pred_test = logmodel.predict( new_x_test )\n",
        "print( pred_test[0] )\n",
        "log_acc = metrics.accuracy_score(y_test, log_pred_test )\n",
        "print( \"test accuracy\", log_acc )\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1peSMAMJAksy"
      },
      "source": [
        "## Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aEvO2-V6AonD"
      },
      "outputs": [],
      "source": [
        "theEpochs = 2\n",
        "\n",
        "theActivation = tf.keras.activations.relu\n",
        "\n",
        "\n",
        "units_01 = int( 2*total_size )\n",
        "units_02 = units_01\n",
        "\n",
        "DENSE_LAYER_01 = tf.keras.layers.Dense( units=units_01, activation=theActivation )\n",
        "DENSE_LAYER_02 = tf.keras.layers.Dense( units=units_02, activation=theActivation )\n",
        "DENSE_LAYER_XX = tf.keras.layers.Dense(10, activation=tf.nn.softmax )\n",
        "\n",
        "DROPOUT_LAYER = tf.keras.layers.Dropout( 0.2 )\n",
        "\n",
        "\n",
        "theOptimizer = tf.keras.optimizers.Adam()\n",
        "theLossMetric = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "theSplit = 0.2\n",
        "theBatchSize = 32\n",
        "verboseFlag = True\n",
        "\n",
        "theTensorFlowSaveFile = \"TF_Number_Model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jFvD6MNAr_x",
        "outputId": "0a31dc2d-9de3-418a-8c13-ada2ba39f0e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This might take a while ... maybe 15+ minutes ...depends on your computer.\n",
            "Epoch 1/2\n",
            "1500/1500 [==============================] - 44s 29ms/step - loss: 0.4931 - accuracy: 0.8159 - val_loss: 0.3711 - val_accuracy: 0.8663\n",
            "Epoch 2/2\n",
            "1500/1500 [==============================] - 44s 29ms/step - loss: 0.3833 - accuracy: 0.8567 - val_loss: 0.3757 - val_accuracy: 0.8582\n",
            "Execution Time In Seconds =  89.0\n",
            "Execution Time In Minutes =  1.5\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Build the Model\n",
        "\n",
        "print(\"This might take a while ... maybe 15+ minutes ...depends on your computer.\")\n",
        "start_time = time.time()\n",
        "\n",
        "nn_model = tf.keras.models.Sequential()\n",
        "nn_model.add( tf.keras.layers.Flatten( input_shape=input_shape ) )\n",
        "nn_model.add( DENSE_LAYER_01 )\n",
        "nn_model.add( DROPOUT_LAYER )\n",
        "nn_model.add( DENSE_LAYER_02 )\n",
        "nn_model.add( DENSE_LAYER_XX )\n",
        "#model.compile( optimizer=theOptimizer, loss=theLossMetric )\n",
        "nn_model.compile( optimizer=theOptimizer, loss=theLossMetric, metrics=['accuracy'] )\n",
        "#model.fit(x_train, y_train, epochs=theEpochs, verbose = verboseFlag )\n",
        "nn_model.fit(x_train, y_train, epochs=theEpochs, validation_split=theSplit, batch_size=theBatchSize, verbose = verboseFlag )\n",
        "\n",
        "\n",
        "Time_In_Seconds = round( time.time()-start_time, 0 )\n",
        "Time_In_Minutes = round( Time_In_Seconds / 60, 1 )\n",
        "print(\"Execution Time In Seconds = \", Time_In_Seconds )\n",
        "print(\"Execution Time In Minutes = \", Time_In_Minutes )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwQIaMSTAwmh",
        "outputId": "1c301f6c-7fb0-4733-f0d6-bd90483c9743"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 5ms/step\n",
            "WHO =  5227  Predicted = 1  Actual =  1\n",
            "WHO =  8615  Predicted = 3  Actual =  3\n",
            "WHO =  6273  Predicted = 4  Actual =  6\n",
            "WHO =  4745  Predicted = 1  Actual =  1\n",
            "WHO =  3187  Predicted = 2  Actual =  2\n",
            " --------- \n",
            "accuracy =  0.8509\n"
          ]
        }
      ],
      "source": [
        "probs = nn_model.predict( x_test )\n",
        "\n",
        "pred_list = []\n",
        "for p in probs :\n",
        "    pred_list.append( np.argmax( p ) )\n",
        "nn_pred = np.array( pred_list )\n",
        "nn_acc_score = metrics.accuracy_score( y_test, nn_pred)\n",
        "\n",
        "for i in range(5) :\n",
        "    who = getRandomIndex( x_test )\n",
        "    print(\"WHO = \", who, \" Predicted =\", nn_pred[who], \" Actual = \", y_test[who] )\n",
        "\n",
        "print(\" --------- \")\n",
        "print(\"accuracy = \", nn_acc_score)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rKJ5P3RCB_j1"
      },
      "source": [
        "## NN optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3MdLMpLEGI2",
        "outputId": "e3f7d857-19ad-493c-e4fc-da3c02106bea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1568"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "int( 2*total_size )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "rFqbvgwlCBYD"
      },
      "outputs": [],
      "source": [
        "import keras_tuner as kt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "L6g9SQ5QCsfK"
      },
      "outputs": [],
      "source": [
        "def create_model(hp):\n",
        "    nn_model = tf.keras.models.Sequential()\n",
        "\n",
        "    # Allow kerastuner to decide which activation function to use in hidden layers\n",
        "    activation = hp.Choice('activation',['relu','sigmoid','selu','softmax'])\n",
        "    optimizers = ['adam','SGD','AdamW']\n",
        "    lr_min, lr_max = 1e-4, 1e-1\n",
        "\n",
        "    optimizer = hp.Choice('optimizer', optimizers)\n",
        "    lr = hp.Float('learning_rate', min_value=lr_min, max_value=lr_max, sampling='log')\n",
        "    nn_model.add( tf.keras.layers.Flatten( input_shape=input_shape ) )\n",
        "    # Allow kerastuner to decide number of neurons in first layer\n",
        "    nn_model.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
        "        min_value=int( 2*total_size ),\n",
        "        max_value=1800,\n",
        "        step=50), activation=activation)) #, input_dim=X_train_scaled.shape[1]\n",
        "\n",
        "    # Allow kerastuner to decide number of hidden layers and neurons in hidden layers\n",
        "    for i in range(hp.Int('num_layers', 1, 3)):\n",
        "        nn_model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
        "            min_value=100,\n",
        "            max_value=1800,\n",
        "            step=400),\n",
        "            activation=activation))\n",
        "    \n",
        "    nn_model.add(tf.keras.layers.Dense(units=10, activation=\"softmax\"))\n",
        "\n",
        "    if optimizer == \"adam\":\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    elif optimizer == \"SGD\":\n",
        "        optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
        "    elif optimizer == \"AdamW\":\n",
        "        optimizer = tf.keras.optimizers.AdamW(learning_rate=lr)\n",
        "    else:\n",
        "        raise(\"Not supported optimizer\")\n",
        "\n",
        "    # Compile the model\n",
        "    nn_model.compile(loss=\"SparseCategoricalCrossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "    \n",
        "    return nn_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-kXyZPm7CvAT"
      },
      "outputs": [],
      "source": [
        "tunerx = kt.Hyperband(create_model, \n",
        "                     objective=\"val_accuracy\",\n",
        "                     max_epochs=3,\n",
        "                     hyperband_iterations=2,\n",
        "                     overwrite=True,\n",
        "                     project_name='1111')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "haRqe9aUCzVz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 12 Complete [00h 03m 28s]\n",
            "val_accuracy: 0.10000000149011612\n",
            "\n",
            "Best val_accuracy So Far: 0.8730999827384949\n",
            "Total elapsed time: 00h 24m 13s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ],
      "source": [
        "tunerx.search(x_train, y_train,epochs=3,validation_data=(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "gXUQmO3JGvKC"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'tuner2' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_model \u001b[39m=\u001b[39m tuner2\u001b[39m.\u001b[39mget_best_models(\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m      2\u001b[0m nn_model_loss, nn_model_accuracy \u001b[39m=\u001b[39m best_model\u001b[39m.\u001b[39mevaluate(x_test,y_test,verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoss: \u001b[39m\u001b[39m{\u001b[39;00mnn_model_loss\u001b[39m}\u001b[39;00m\u001b[39m, Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mnn_model_accuracy\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'tuner2' is not defined"
          ]
        }
      ],
      "source": [
        "best_model = tuner2.get_best_models(1)[0]\n",
        "nn_model_loss, nn_model_accuracy = best_model.evaluate(x_test,y_test,verbose=2)\n",
        "print(f\"Loss: {nn_model_loss}, Accuracy: {nn_model_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVAuDuHVHAJV"
      },
      "outputs": [],
      "source": [
        "best_model.save('bestmodel')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KYvum6yvHL6o"
      },
      "source": [
        "## Testing our saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofgfsV3PHOv3"
      },
      "outputs": [],
      "source": [
        "new_model = tf.keras.models.load_model( 'bestmodel' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nm3OA-9fHQ6C"
      },
      "outputs": [],
      "source": [
        "newest_pred = new_model.predict( x_test ) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvOhGWhrHYEx"
      },
      "outputs": [],
      "source": [
        "who=getRandomIndex( x_test )\n",
        "print( newest_pred[who]) # probability score\n",
        "result = np.argmax( list(newest_pred[who]) )\n",
        "print(\"predict=\",result,\"actual=\",y_test[who])\n",
        "plt.imshow( x_test[who], plt.cm.binary )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
