t.test(df$weight ~ df$Diet, var.equal = TRUE)
t.test(s3_df$weight ~ s3_df$Diet, var.equal = TRUE)
# There are multiple ways to approach the subsetting task. The method you choose is up
# to you.
s3_df2 <- ChickWeight[ChickWeight$Diet == 3 & (ChickWeight$Time == 21 | ChickWeight$Time == 20),]
only20 <- ChickWeight[ChickWeight$Diet == 3 & ChickWeight$Time == 20,]
only21 <- ChickWeight[ChickWeight$Diet == 3 & ChickWeight$Time == 21,]
only20[1:6]
# There are multiple ways to approach the subsetting task. The method you choose is up
# to you.
s3_df2 <- ChickWeight[ChickWeight$Diet == 3 & (ChickWeight$Time == 21 | ChickWeight$Time == 20),]
only20 <- ChickWeight[ChickWeight$Diet == 3 & ChickWeight$Time == 20,"weight"]
only21 <- ChickWeight[ChickWeight$Diet == 3 & ChickWeight$Time == 21,"weight"]
only20[1:6]
# The first six (6) elements of your Time == 20 vector should match those below:
# [1] 235 291 156 327 361 225
s3_df2 <- data.frame(only20,onl21)
s3_df2 <- data.frame(only20,only21)
View(s3_df2)
ggplot(data =s3_df2,aes(x=only20,y=only21)) +
geom_point()
ggplot(data =s3_df2,aes(x=only20,y=only21)) +
geom_point() +
geom_abline(intercept=0, slope=1, color= 'red')
ggplot(data =s3_df2,aes(x=only20,y=only21)) +
geom_point() +
geom_abline(intercept=0, slope=1, color= 'red') +
ggtitle('Weight from 20 to 21') +
theme(plot.title = element_text(hjust = 0.5)) +
ggplot(data =s3_df2,aes(x=only20,y=only21)) +
geom_point() +
geom_abline(intercept=0, slope=1, color= 'red') +
ggtitle('Weight from 20 to 21') +
theme(plot.title = element_text(hjust = 0.5))
t_stat <- mean(s3_df2) / (sd(s3_df2)) / sqrt(length(s3_df2))
s3_df2_diff <- s3_df2$only21 = s3_df2$only20
s3_df2_diff <- s3_df2$only21 = s3_df2$only20
s3_df2_diff <- s3_df2$only21 = s3_df2$only20
s3_df2_diff <- s3_df2$only21 - s3_df2$only20
t_stat <- mean(s3_df2_diff) / (sd(s3_df2_diff)) / sqrt(length(s3_df2_diff))
p_val <- pt(q = t_stat, df= length(s3_df2_diff)-1, lower.tail = False)
s3_df2_diff <- s3_df2$only21 - s3_df2$only20
t_stat <- mean(s3_df2_diff) / (sd(s3_df2_diff)) / sqrt(length(s3_df2_diff))
p_val <- pt(q = t_stat, df= length(s3_df2_diff)-1, lower.tail = FALSE)
crit_t_val <- qt(p = 0-.95, df = length(s3_df2_diff)-1)
lower <- mean(s3_df2_diff) - crit_t_val * sd(s3_df2_diff) / sqrt(length(s3_df2_diff))
list("t stat" = t_stat,
"p val" = p_val,
"crit t" = crit_t_val,
"conf int" = list(lower=lower, upper = "inf"))
s3_df2_diff <- s3_df2$only21 - s3_df2$only20
t_stat <- mean(s3_df2_diff) / (sd(s3_df2_diff) / sqrt(length(s3_df2_diff)))
p_val <- pt(q = t_stat, df= length(s3_df2_diff)-1, lower.tail = FALSE)
crit_t_val <- qt(p = 0-.95, df = length(s3_df2_diff)-1)
lower <- mean(s3_df2_diff) - crit_t_val * sd(s3_df2_diff) / sqrt(length(s3_df2_diff))
list("t stat" = t_stat,
"p val" = p_val,
"crit t" = crit_t_val,
"conf int" = list(lower=lower, upper = "inf"))
s3_df2_diff <- s3_df2$only21 - s3_df2$only20
t_stat <- mean(s3_df2_diff) / (sd(s3_df2_diff) / sqrt(length(s3_df2_diff)))
p_val <- pt(q = t_stat, df= length(s3_df2_diff)-1, lower.tail = FALSE)
crit_t_val <- qt(p = 0.95, df = length(s3_df2_diff)-1)
lower <- mean(s3_df2_diff) - crit_t_val * sd(s3_df2_diff) / sqrt(length(s3_df2_diff))
list("t stat" = t_stat,
"p val" = p_val,
"crit t" = crit_t_val,
"conf int" = list(lower=lower, upper = "inf"))
s4_x <- c(seq(400,1400,1))
max(s4_x)
data(Nile, package = "datasets")
s4_mean <- mean(Nile)
s4_std <- sd(Nile)
s4_x <- c(seq(400,1400,1))
curve(dnorm(x,mean = s4_mean, sd = s4_std), col = 'orange', lwd=2, add=TRUE)
data(Nile, package = "datasets")
s4_mean <- mean(Nile)
s4_std <- sd(Nile)
s4_x <- c(seq(400,1400,1))
hist(Nile, freq = FALSE, col = 'blue', xlab= 'flow', main = 'title')
curve(dnorm(x,mean = s4_mean, sd = s4_std), col = 'orange', lwd=2, add=TRUE)
ggplot(data=Nile) +
stat_qq()
skewness(Nile)
kurtosis(Nile)
par(mfrow = c(1, 2))
qqnorm(Nile, col = 'purple', main = c("QQ"))
qqline(Nile)
boxplot(Nile, col = 'purple', main = c("Boxplot"), notch = TRUE)
set.seed(124)
s4b_n <- 1000
sample1 <- c()
sample2 <- c()
for (i in 1:s4b_n) {
s4b_samp <- sample(Nile, 16, replace = TRUE)
sample1 <- c(sample1,mean(s4b_samp))
}
set.seed(124)
s4b_n <- 1000
sample1 <- c()
sample2 <- c()
for (i in 1:s4b_n) {
s4b_samp <- sample(Nile, 16, replace = TRUE)
sample1 <- c(sample1,mean(s4b_samp))
}
sam1_mean <- mean(sample1)
sam1_std <- sd(sample1)
sam1_var <- var(sample1)
sam1_holder <- c('sample1', sam1_mean, sam1_std, sam1_var)
samp1_df <- data.frame(t(sam1_holder))
set.seed(127)
for (j in 1:s4b_n) {
s4b_samp <- sample(Nile, 16, replace = TRUE)
sample2 <- c(sample2,mean(s4b_samp))
}
sam2_mean <- mean(sample2)
sam2_std <- sd(sample2)
sam2_var <- var(sample2)
sam2_holder <- c('sample2', sam2_mean, sam2_std, sam2_var)
samp2_df <- data.frame(t(sam2_holder))
col_name <- c('Sample','Mean','Std Dev', 'Variance')
s4b_df <- rbind(samp1_df,samp2_df)
colnames(s4b_df) <- col_name
s4b_df
# Create histograms of "sample1" and "sample2" with normal density curves superimposed
par(mfrow = c(1,2))
hist(sample1, freq= FALSE, col = 'blue', xlab = 'Flow Averages', xlim = c(750,1050), ylim = c(0,0.025, main = "Sample1"))
# Create histograms of "sample1" and "sample2" with normal density curves superimposed
par(mfrow = c(1,2))
hist(sample1, freq= FALSE, col = 'blue', xlab = 'Flow Averages', xlim = c(750,1050), ylim = c(0,0.025), main = "Sample1")
curve(dnorm(x,mean = s4_mean, sd = s4_std), col = 'orange', lwd=2, add=TRUE)
hist(sample2, freq= FALSE, col = 'blue', xlab = 'Flow Averages', xlim = c(750,1050), ylim = c(0,0.025), main = "Sample2")
curve(dnorm(x,mean = s4_mean, sd = s4_std), col = 'orange', lwd=2, add=TRUE)
# Create histograms of "sample1" and "sample2" with normal density curves superimposed
par(mfrow = c(1,2))
hist(sample1, freq= FALSE, col = 'blue', xlab = 'Flow Averages', xlim = c(750,1050), ylim = c(0,0.025), main = "Sample1")
curve(dnorm(x,mean = sam1_mean, sd = sam1_std), col = 'orange', lwd=2, add=TRUE)
hist(sample2, freq= FALSE, col = 'blue', xlab = 'Flow Averages', xlim = c(750,1050), ylim = c(0,0.025), main = "Sample2")
curve(dnorm(x,mean = sam2_mean, sd = sam2_std), col = 'orange', lwd=2, add=TRUE)
data(warpbreaks, package = "datasets")
str(warpbreaks)
hist(warpbreaks$breaks)
abline(v = median(warpbreaks$breaks), lty = 2, col = 'red')
warpbreaks$number <- factor(ifelse(warpbreaks$breaks < median(warpbreaks$breaks),"below","avobe"))
summary(warpbreaks)
table(warpbreaks$wool,warpbreaks$number)
data(warpbreaks, package = "datasets")
str(warpbreaks)
median_breaks <- median(warpbreaks$breaks)
hist(warpbreaks$breaks)
abline(v = median_breaks, lty = 2, col = 'red')
warpbreaks$number <- factor(ifelse(warpbreaks$breaks < median_breaks,"below","avobe"))
summary(warpbreaks)
s5_table <- table(warpbreaks$tension,warpbreaks$wool)
s5_table
chisq.test ( x = s5_table, correct= FALSE)
View(warpbreaks)
data(warpbreaks, package = "datasets")
str(warpbreaks)
median_breaks <- median(warpbreaks$breaks)
hist(warpbreaks$breaks)
abline(v = median_breaks, lty = 2, col = 'red')
warpbreaks$number <- factor(ifelse(warpbreaks$breaks < median_breaks,"below","above"))
summary(warpbreaks)
s5_table <- table(warpbreaks$tension,warpbreaks$wool)
s5_table
tbl <- table(warpbreaks$tension, warpbreaks$number)
mar_tbl <- addmargins(tbl)
e11 <- mar_tbl[4, 1] * mar_tbl[1, 3] / mar_tbl[4, 3]
e12 <- mar_tbl[4, 2] * mar_tbl[1, 3] / mar_tbl[4, 3]
e21 <- mar_tbl[4, 1] * mar_tbl[2, 3] / mar_tbl[4, 3]
e22 <- mar_tbl[4, 2] * mar_tbl[2, 3] / mar_tbl[4, 3]
tbl <- table(warpbreaks$tension, warpbreaks$number)
mar_tbl <- addmargins(tbl)
mar_tbl
e11 <- mar_tbl[4, 1] * mar_tbl[1, 3] / mar_tbl[4, 3]
e12 <- mar_tbl[4, 2] * mar_tbl[1, 3] / mar_tbl[4, 3]
e21 <- mar_tbl[4, 1] * mar_tbl[2, 3] / mar_tbl[4, 3]
e22 <- mar_tbl[4, 2] * mar_tbl[2, 3] / mar_tbl[4, 3]
data(warpbreaks, package = "datasets")
str(warpbreaks)
median_breaks <- median(warpbreaks$breaks)
hist(warpbreaks$breaks)
abline(v = median_breaks, lty = 2, col = 'red')
warpbreaks$number <- factor(ifelse(warpbreaks$breaks < median_breaks,"below","above"))
summary(warpbreaks)
s5_table <- table(warpbreaks$tension,warpbreaks$number)
s5_table
chisq.test(x = s5_table, correct= FALSE)
#conclusion, something is wrong here?
tbl <- table(warpbreaks$tension, warpbreaks$number)
mar_tbl <- addmargins(tbl)
mar_tbl
mar_tbl[4, 1]
e11 <- mar_tbl[4, 1] * mar_tbl[1, 3] / mar_tbl[4, 3]
e12 <- mar_tbl[4, 2] * mar_tbl[1, 3] / mar_tbl[4, 3]
e21 <- mar_tbl[4, 1] * mar_tbl[2, 3] / mar_tbl[4, 3]
e22 <- mar_tbl[4, 2] * mar_tbl[2, 3] / mar_tbl[4, 3]
chisq.test
chi_sq <- (tbl[1,1] - e11)^2 / e11 +
(tbl[1,2] - e12)^2 / e12 +
(tbl[1,2] - e12)^2 / e12 +
(tbl[1,2] - e12)^2 / e12 +
```
tbl <- table(warpbreaks$tension, warpbreaks$number)
mar_tbl <- addmargins(tbl)
mar_tbl
mar_tbl[4, 1]
e11 <- mar_tbl[4, 1] * mar_tbl[1, 3] / mar_tbl[4, 3]
e12 <- mar_tbl[4, 2] * mar_tbl[1, 3] / mar_tbl[4, 3]
e21 <- mar_tbl[4, 1] * mar_tbl[2, 3] / mar_tbl[4, 3]
e22 <- mar_tbl[4, 2] * mar_tbl[2, 3] / mar_tbl[4, 3]
e31 <- mar_tbl[4, 1] * mar_tbl[3, 3] / mar_tbl[4, 3]
e32 <- mar_tbl[4, 2] * mar_tbl[3, 3] / mar_tbl[4, 3]
chi_sq <- (tbl[1,1] - e11)^2 / e11 +
(tbl[1,2] - e12)^2 / e12 +
(tbl[2,1] - e21)^2 / e21 +
(tbl[2,2] - e22)^2 / e22 +
(tbl[3,1] - e31)^2 / e31 +
(tbl[3,2] - e32)^2 / e32
chi_sq
tbl <- table(warpbreaks$tension, warpbreaks$number)
mar_tbl <- addmargins(tbl)
mar_tbl
e11 <- mar_tbl[4, 1] * mar_tbl[1, 3] / mar_tbl[4, 3]
e12 <- mar_tbl[4, 2] * mar_tbl[1, 3] / mar_tbl[4, 3]
e21 <- mar_tbl[4, 1] * mar_tbl[2, 3] / mar_tbl[4, 3]
e22 <- mar_tbl[4, 2] * mar_tbl[2, 3] / mar_tbl[4, 3]
e31 <- mar_tbl[4, 1] * mar_tbl[3, 3] / mar_tbl[4, 3]
e32 <- mar_tbl[4, 2] * mar_tbl[3, 3] / mar_tbl[4, 3]
chi_sq <- (tbl[1,1] - e11)^2 / e11 +
(tbl[1,2] - e12)^2 / e12 +
(tbl[2,1] - e21)^2 / e21 +
(tbl[2,2] - e22)^2 / e22 +
(tbl[3,1] - e31)^2 / e31 +
(tbl[3,2] - e32)^2 / e32
list ('chisq' = chi_sq,
'p-val' = pchisq(q=chi_sq, df = (nrow(tbl)-1 * (ncol(tbl)-1)), lower.tail = FALSE))
chisq_function <- function(x) {
# Code for calculating the expected values
mar_tbl <- addmargins(x)
e11 <- mar_tbl[4, 1] * mar_tbl[1, 3] / mar_tbl[4, 3]
e12 <- mar_tbl[4, 2] * mar_tbl[1, 3] / mar_tbl[4, 3]
e21 <- mar_tbl[4, 1] * mar_tbl[2, 3] / mar_tbl[4, 3]
e22 <- mar_tbl[4, 2] * mar_tbl[2, 3] / mar_tbl[4, 3]
e31 <- mar_tbl[4, 1] * mar_tbl[3, 3] / mar_tbl[4, 3]
e32 <- mar_tbl[4, 2] * mar_tbl[3, 3] / mar_tbl[4, 3]
# Code for calculating the chi-squared
chi_sq <- (tbl[1,1] - e11)^2 / e11 +
(tbl[1,2] - e12)^2 / e12 +
(tbl[2,1] - e21)^2 / e21 +
(tbl[2,2] - e22)^2 / e22 +
(tbl[3,1] - e31)^2 / e31 +
(tbl[3,2] - e32)^2 / e32
# Code for calculating the degrees of freedom and p-value
s5_df = (nrow(x)-1 * (ncol(x)-1))
s5_pv = pchisq(q=chi_sq, s5_df, lower.tail = FALSE)
# Code to ouput the chi-squared, degrees of freedom and p-value
list ('chisq' = chi_sq,
'p-val' = s5_pv)
}
chisq_function(tbl)
# DO NOT ADD OR REVISE CODE HERE
knitr::opts_chunk$set(echo = TRUE, eval = TRUE)
library(moments)  # install.packages("moments")
q1_1_np <- .05*100
q1_1_dpois <- dpois(0,q1_1_np)
q1_1_dpois
q1_1_dbinom <- dbinom(0,100,0.05)
q1_1_dbinom
q1_2_np <- .05*100
q1_2_ppois <- ppois(6, q1_2_np, lower.tail = TRUE)
q1_2_ppois
q1_2_pbinom <- pbinom(6, 100, 0.05, lower.tail = TRUE)
q1_2_pbinom
q1_3_n <- 100
q1_3_p <- 0.25
q1_3_np <- q1_3_n * q1_3_p
q1_3_sd <- sqrt(q1_3_n * q1_3_p * (1 - q1_3_p))
#dont forget to +.5 and -.5 for pnorm
q1_3_pnorm <- pnorm(25.5, q1_3_np, q1_3_sd) - pnorm(24.5, q1_3_np, q1_3_sd)
q1_3_pnorm
q1_3_dbinom <- dbinom(25, q1_3_n, q1_3_p)
q1_3_dbinom
q1_4_n <- 100
q1_4_p <- 0.25
q1_4_np <- q1_4_n * q1_4_p
q1_4_sd <- sqrt(q1_4_n * q1_4_p * (1 - q1_4_p))
#dont forget to -.5 since we're doing less than
q1_4_pnorm <- pnorm(19.5, q1_4_np, q1_4_sd)
q1_4_pnorm
#don't forget to -1 since this is inclusive and we want 19 or less
q1_4_pbinom <- pbinom(19, q1_4_n, q1_4_p, lower.tail=TRUE)
q1_4_pbinom
library(ggplot2)
library(gridExtra)
q1b_n <- 100
q1b_p <- 0.05
q1b_np <- 100*0.05
x_axis <- c(seq(0,10))
pois <- dpois(x_axis,q1b_np)
left_df <- data.frame(x_axis,pois)
binom <- dbinom(x_axis, q1b_n, q1b_p)
right_df <- data.frame(x_axis,binom)
left <- ggplot(data=left_df, aes(x = x_axis, y = pois)) +
geom_bar(stat = 'identity', fill = 'pink') +
ggtitle('Poisson') +
theme(plot.title = element_text(hjust = 0.5))
right <- ggplot(data=right_df, aes(x = x_axis, y = binom)) +
geom_bar(stat = 'identity', fill = 'purple') +
ggtitle('Binomial') +
theme(plot.title = element_text(hjust = 0.5))
grid.arrange(left, right, ncol=2)
q1c1_x <- c(seq(0,6))
q1c1_y <- c(0.214, 0.230, 0.240, 0.182, 0.130, 0.003, 0.001)
q1c1_df <- data.frame(x = q1c1_x,y = q1c1_y)
q1c1_ev <- round(sum(q1c1_df$x * q1c1_df$y), 1)
q1c1_var <- round(sum(q1c1_df$y * (q1c1_df$x - q1c1_ev)^2), 1)
q1c1_ev
q1c1_var
q1c2_plot <- ggplot(data=q1c1_df,aes(x=x,y=cumsum(y))) +
geom_step() +
geom_hline(yintercept=0.5,color = 'red') +
annotate('text',x = 1.5, y= .55, label = 'median = 2')
q1c2_plot
data(faithful, package = "datasets")
summary(faithful)
hist(faithful$waiting)
sum(faithful$waiting > 70 & faithful$eruptions < 3.5)/sum(faithful$waiting > 70)
q2a1_df <- faithful[faithful$waiting > 70 & faithful$eruptions < 3,]
q2a1_df
q2a1_scatter <- ggplot(data=faithful,aes(x=waiting,y=eruptions)) +
geom_point() +
geom_point(data=q2a1_df,aes(x=waiting,y=eruptions),color='red',size=2) +
geom_hline(yintercept = 3, color = 'purple') +
geom_vline(xintercept = 70, color = 'purple') +
annotate('text',x = 75, y= 2.6, label = '> 70 & < 3')
q2a1_scatter
q2b_df <- as.data.frame(matrix(faithful$waiting, ncol = 2, byrow = TRUE))
ggplot(data=q2b_df,aes(x=V1,y=V2)) +
geom_point() +
ggtitle('Consecutive Waiting Times') +
theme(plot.title = element_text(hjust = 0.5)) +
xlab('First Waiting Time') +
ylab('Second Waiting Time') +
geom_vline(xintercept = median(q2b_df$V1), color = 'red', linetype=2) +
geom_hline(yintercept = median(q2b_df$V2), color = 'red', linetype=2)
cor.test(q2b_df$V1, q2b_df$V2, alternative = c("two.sided"),
method = c("kendall"),
conf.level = 0.05)
#not sure if the question meant 95% but the documentation says the kendall
#method doesn't actually use this parameter, only the pearson method
cor.test(q2b_df$V1, q2b_df$V2, alternative = c("two.sided"),
method = c("pearson"),
conf.level = 0.95)
# load "ChickWeight" dataset
data(ChickWeight, package = "datasets")
# There are multiple ways to approach the subsetting task. The method you choose is up
# to you.
s3_df <- ChickWeight[ChickWeight$Time == 21 & (ChickWeight$Diet == 1 | ChickWeight$Diet == 3),]
head(s3_df)
# The values in your subsetted data frame should match those below:
# > head(df)
#    weight Time Chick Diet
# 12    205   21     1    1
# 24    215   21     2    1
# 36    202   21     3    1
# 48    157   21     4    1
# 60    223   21     5    1
# 72    157   21     6    1
par(mfrow = c(1,2))
boxplot(weight ~ droplevels(Diet), data= s3_df, subset = Diet=="1", xlab = 'Diet', ylab = 'Weight')
boxplot(weight ~ droplevels(Diet), data= s3_df, subset = Diet=="3", xlab = 'Diet', ylab = 'Weight')
t.test(s3_df$weight ~ s3_df$Diet, var.equal = TRUE)
# There are multiple ways to approach the subsetting task. The method you choose is up
# to you.
only20 <- ChickWeight[ChickWeight$Diet == 3 & ChickWeight$Time == 20,"weight"]
only21 <- ChickWeight[ChickWeight$Diet == 3 & ChickWeight$Time == 21,"weight"]
s3_df2 <- data.frame(only20,only21)
only20[1:6]
# The first six (6) elements of your Time == 20 vector should match those below:
# [1] 235 291 156 327 361 225
ggplot(data =s3_df2,aes(x=only20,y=only21)) +
geom_point() +
geom_abline(intercept=0, slope=1, color= 'red') +
ggtitle('Weight from 20 to 21') +
theme(plot.title = element_text(hjust = 0.5))
s3_df2_diff <- s3_df2$only21 - s3_df2$only20
t_stat <- mean(s3_df2_diff) / (sd(s3_df2_diff) / sqrt(length(s3_df2_diff)))
p_val <- pt(q = t_stat, df= length(s3_df2_diff)-1, lower.tail = FALSE)
crit_t_val <- qt(p = 0.95, df = length(s3_df2_diff)-1)
lower <- mean(s3_df2_diff) - crit_t_val * sd(s3_df2_diff) / sqrt(length(s3_df2_diff))
list("t stat" = t_stat,
"p val" = p_val,
"crit t" = crit_t_val,
"conf int" = list(lower=lower, upper = "inf"))
data(Nile, package = "datasets")
s4_mean <- mean(Nile)
s4_std <- sd(Nile)
s4_x <- c(seq(400,1400,1))
hist(Nile, freq = FALSE, col = 'blue', xlab= 'flow', main = 'title')
curve(dnorm(x,mean = s4_mean, sd = s4_std), col = 'orange', lwd=2, add=TRUE)
skewness(Nile)
kurtosis(Nile)
par(mfrow = c(1, 2))
qqnorm(Nile, col = 'purple', main = c("QQ"))
qqline(Nile)
boxplot(Nile, col = 'purple', main = c("Boxplot"), notch = TRUE)
set.seed(124)
s4b_n <- 1000
sample1 <- c()
sample2 <- c()
for (i in 1:s4b_n) {
s4b_samp <- sample(Nile, 16, replace = TRUE)
sample1 <- c(sample1,mean(s4b_samp))
}
sam1_mean <- mean(sample1)
sam1_std <- sd(sample1)
sam1_var <- var(sample1)
sam1_holder <- c('sample1', sam1_mean, sam1_std, sam1_var)
samp1_df <- data.frame(t(sam1_holder))
set.seed(127)
for (j in 1:s4b_n) {
s4b_samp <- sample(Nile, 16, replace = TRUE)
sample2 <- c(sample2,mean(s4b_samp))
}
sam2_mean <- mean(sample2)
sam2_std <- sd(sample2)
sam2_var <- var(sample2)
sam2_holder <- c('sample2', sam2_mean, sam2_std, sam2_var)
samp2_df <- data.frame(t(sam2_holder))
col_name <- c('Sample','Mean','Std Dev', 'Variance')
s4b_df <- rbind(samp1_df,samp2_df)
colnames(s4b_df) <- col_name
s4b_df
# Create histograms of "sample1" and "sample2" with normal density curves superimposed
par(mfrow = c(1,2))
hist(sample1, freq= FALSE, col = 'blue', xlab = 'Flow Averages', xlim = c(750,1050), ylim = c(0,0.025), main = "Sample1")
curve(dnorm(x,mean = sam1_mean, sd = sam1_std), col = 'orange', lwd=2, add=TRUE)
hist(sample2, freq= FALSE, col = 'blue', xlab = 'Flow Averages', xlim = c(750,1050), ylim = c(0,0.025), main = "Sample2")
curve(dnorm(x,mean = sam2_mean, sd = sam2_std), col = 'orange', lwd=2, add=TRUE)
data(warpbreaks, package = "datasets")
str(warpbreaks)
median_breaks <- median(warpbreaks$breaks)
hist(warpbreaks$breaks)
abline(v = median_breaks, lty = 2, col = 'red')
warpbreaks$number <- factor(ifelse(warpbreaks$breaks < median_breaks,"below","above"))
summary(warpbreaks)
s5_table <- table(warpbreaks$tension,warpbreaks$number)
s5_table
chisq.test(x = s5_table, correct= FALSE)
#conclusion: the relationship is worth looking at. Since p < 0.05, we can reject the null hypothesis of the chisq test (tension and number are independent). This means we can assert that they are dependent.
tbl <- table(warpbreaks$tension, warpbreaks$number)
mar_tbl <- addmargins(tbl)
mar_tbl
e11 <- mar_tbl[4, 1] * mar_tbl[1, 3] / mar_tbl[4, 3]
e12 <- mar_tbl[4, 2] * mar_tbl[1, 3] / mar_tbl[4, 3]
e21 <- mar_tbl[4, 1] * mar_tbl[2, 3] / mar_tbl[4, 3]
e22 <- mar_tbl[4, 2] * mar_tbl[2, 3] / mar_tbl[4, 3]
e31 <- mar_tbl[4, 1] * mar_tbl[3, 3] / mar_tbl[4, 3]
e32 <- mar_tbl[4, 2] * mar_tbl[3, 3] / mar_tbl[4, 3]
chi_sq <- (tbl[1,1] - e11)^2 / e11 +
(tbl[1,2] - e12)^2 / e12 +
(tbl[2,1] - e21)^2 / e21 +
(tbl[2,2] - e22)^2 / e22 +
(tbl[3,1] - e31)^2 / e31 +
(tbl[3,2] - e32)^2 / e32
list ('chisq' = chi_sq,
'p-val' = pchisq(q=chi_sq, df = (nrow(tbl)-1 * (ncol(tbl)-1)), lower.tail = FALSE))
chisq_function <- function(x) {
# Code for calculating the expected values
mar_tbl <- addmargins(x)
e11 <- mar_tbl[4, 1] * mar_tbl[1, 3] / mar_tbl[4, 3]
e12 <- mar_tbl[4, 2] * mar_tbl[1, 3] / mar_tbl[4, 3]
e21 <- mar_tbl[4, 1] * mar_tbl[2, 3] / mar_tbl[4, 3]
e22 <- mar_tbl[4, 2] * mar_tbl[2, 3] / mar_tbl[4, 3]
e31 <- mar_tbl[4, 1] * mar_tbl[3, 3] / mar_tbl[4, 3]
e32 <- mar_tbl[4, 2] * mar_tbl[3, 3] / mar_tbl[4, 3]
# Code for calculating the chi-squared
chi_sq <- (tbl[1,1] - e11)^2 / e11 +
(tbl[1,2] - e12)^2 / e12 +
(tbl[2,1] - e21)^2 / e21 +
(tbl[2,2] - e22)^2 / e22 +
(tbl[3,1] - e31)^2 / e31 +
(tbl[3,2] - e32)^2 / e32
# Code for calculating the degrees of freedom and p-value
s5_df = (nrow(x)-1 * (ncol(x)-1))
s5_pv = pchisq(q=chi_sq, s5_df, lower.tail = FALSE)
# Code to ouput the chi-squared, degrees of freedom and p-value
list ('chisq' = chi_sq,
'p-val' = s5_pv)
}
chisq_function(tbl)
# Below is a function that should return the same values as chisq.test() and your
# function from (5)(d). Here, though, the function loops over the rows and columns
# to calculate the expected values. Ideally, this function would work for any sized
# table.
chisqfun <- function(t) {
x <- addmargins(t)
e <- matrix(0, nrow = nrow(t), ncol = ncol(t), byrow = T)
r <- matrix(0, nrow = nrow(t), ncol = ncol(t), byrow = T)
for (i in 1:dim(t)[1]) {
for (j in 1:dim(t)[2]) {
e[i,j] = x[nrow(x),j] * x[i,ncol(x)]/x[nrow(x), ncol(x)]
r[i,j] = ((x[i,j] - e[i,j])^2)/e[i,j]
}
}
chi <- sum(r)
xdf <- (nrow(t) - 1) * (ncol(t) - 1)
pv <- pchisq(chi, df = xdf, lower.tail = FALSE)
return(list("chi-squared" = chi, "degrees_of_freedom" = xdf, "p-value" = pv))
}
